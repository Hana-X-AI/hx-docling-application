# Charter: HX Docling UI Application

**Document Type**: Project Charter  
**Project Name**: hx-docling-ui  
**Version**: 0.6.0  
**Status**: ✅ APPROVED - All Review Findings Addressed  
**Created**: 2025-12-11  
**Last Updated**: 2025-12-11  
**Author**: Agent Zero (Claude Opus 4.5)  
**Reviewed By**: GitHub Copilot, Code Analysis Agent  
**Deep Review**: See `reviews/charter-review-deep-dive.md` (23 findings - all addressed)  
**Target Executor**: Claude Code

---

## Review Response Summary (v0.6.0)

This version addresses all 23 findings from the Code Analysis Agent review:

| Category | Count | Status |
|----------|-------|--------|
| Critical | 9 | ✅ All Addressed |
| Major | 6 | ✅ All Addressed |
| Minor | 8 | ✅ All Addressed |

**Key Additions:**
- Section 6.8: SSE Resilience Strategy (Critical 1.1)
- Section 7.4.1: Session Edge Cases (Critical 1.2)
- Section 8.6: MCP Error Recovery Strategy (Critical 1.3)
- Section 12.5: Database Management Strategy (Critical 1.4)
- Section 8.7: Health Check Implementation (Critical 1.5)
- Section 7.6.1: Large Document Handling (Critical 1.6)
- Section 7.5.1: File Storage Lifecycle (Critical 1.7)
- Section 13.4: Performance Testing (Critical 1.8)
- Section 13.5: Observability & Monitoring (Critical 1.9)
- Section 8.1.1: Rate Limiting (Major 2.2)
- Section 11.3: URL Input Security (Major 2.5)
- Expanded Appendix A: Error Recovery Mapping (Minor 3.5)
- Updated Appendix C: Comprehensive .gitignore (Minor 3.6)

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Problem Statement](#2-problem-statement)
3. [Vision & Objectives](#3-vision--objectives)
4. [Scope](#4-scope)
5. [Success Criteria](#5-success-criteria)
6. [Technical Architecture](#6-technical-architecture)
7. [Persistent Storage](#7-persistent-storage)
8. [Integration Requirements](#8-integration-requirements)
9. [Extensibility Framework](#9-extensibility-framework)
10. [User Experience Requirements](#10-user-experience-requirements)
11. [Security & Access Control](#11-security--access-control)
12. [Development Environment](#12-development-environment)
13. [Quality Gates](#13-quality-gates)
14. [Constraints & Assumptions](#14-constraints--assumptions)
15. [Risks & Mitigations](#15-risks--mitigations)
16. [Implementation Plan](#16-implementation-plan)
17. [Acceptance Criteria](#17-acceptance-criteria)
18. [Backlog](#18-backlog)
19. [Related Documentation](#19-related-documentation)
20. [Appendices](#20-appendices)

---

## 1. Executive Summary

### 1.1 Purpose

Develop a web-based user interface for the HX-Infrastructure document processing pipeline, enabling users to upload documents and URLs for conversion through the operational Docling MCP Server (hx-docling-mcp-server) backed by IBM Granite Docling 258M VLM.

### 1.2 Business Value

- **Accessibility**: Expose document processing capabilities to non-technical users without MCP protocol knowledge
- **Productivity**: Streamline document ingestion workflows for knowledge base construction
- **Visibility**: Provide real-time feedback on processing status and results
- **Persistence**: Store processing history for audit trail and re-download capability
- **Resilience**: Robust error recovery and reconnection handling
- **Foundation**: Establish extensible platform for future document-centric AI features

### 1.3 Key Constraints

| Constraint | Requirement | Reference |
|------------|-------------|-----------|
| External Dependencies | NONE - All processing via on-premises HX-Infrastructure | Section 14.1 |
| Model Serving | IBM Granite Docling 258M on hx-ollama3-server (operational) | Section 8.4 |
| MCP Interface | hx-docling-mcp-server:8000 (19 tools, 8 used in Phase 1) | Section 8.2 |
| Technology Stack | Next.js 16 + shadcn/ui (per hx-shadcn-server) | Section 6.1 |
| Data Persistence | hx-postgres-server + hx-redis-server | Section 7 |

### 1.4 Project Scope

This charter covers **Phase 1: Development** only.

| Aspect | Value |
|--------|-------|
| **Phase** | Phase 1 - Development |
| **Server** | hx-cc-server (192.168.10.224) |
| **Runtime** | Bare metal Node.js (NO Docker) |
| **Deliverable** | Working application with persistent storage, ready for future deployment |

> **Note**: Production deployment (Docker, hx-dev-server) will be covered in a separate Phase 2 charter.

---

## 2. Problem Statement

### 2.1 Current State

The Docling MCP Server is fully operational with 19 tools exposed via HTTP/SSE/stdio transports. However, accessing these capabilities currently requires:

- Direct MCP protocol knowledge (JSON-RPC 2.0)
- CLI tools or custom integrations
- Technical understanding of tool parameters and response formats

### 2.2 Gap Analysis

| Capability | MCP Server | User Need | Gap |
|------------|------------|-----------|-----|
| Document upload | ✅ `convert_pdf`, `convert_docx`, `convert_xlsx`, `convert_pptx` | Drag-drop interface | UI required |
| URL processing | ✅ `convert_url` | Paste URL, one-click process | UI required |
| Progress tracking | ✅ SSE streaming | Visual progress indicator | UI required |
| Result viewing | ✅ JSON/Markdown/HTML export | Rendered preview | UI required |
| Job history | ❌ Not persisted | View past conversions | **In Scope** |
| Result persistence | ❌ Ephemeral | Re-download past results | **In Scope** |

### 2.3 Target Users

| User Type | Use Case | Technical Level |
|-----------|----------|-----------------|
| Knowledge Workers | Upload documents for RAG ingestion | Low |
| Data Engineers | Batch URL processing for corpus building | Medium |
| AI Developers | Test document processing before pipeline integration | High |
| Stakeholders | Demo document AI capabilities | Low |

---

## 3. Vision & Objectives

### 3.1 Vision Statement

> A clean, professional document processing interface that makes HX-Infrastructure's Docling capabilities accessible to any user while providing extensibility hooks for future AI-powered document workflows.

### 3.2 Primary Objectives

| ID | Objective | Measurable Outcome |
|----|-----------|-------------------|
| OBJ-1 | Enable document upload via web UI | Users can drag-drop PDF/DOCX/XLSX/PPTX/images |
| OBJ-2 | Enable URL-based processing | Users can paste URLs for web page conversion |
| OBJ-3 | Provide real-time progress feedback | SSE-based progress updates with resilient reconnection |
| OBJ-4 | Display conversion results | Rendered Markdown/HTML with download options |
| OBJ-5 | Persist processing history | Users can view and re-download past conversions |
| OBJ-6 | Provide robust error recovery | Clear error messages with actionable recovery paths |

### 3.3 Non-Objectives (Explicit Exclusions)

| Exclusion | Rationale |
|-----------|-----------|
| User authentication | Defer to future phase (AD integration via hx-dc-server) |
| Multi-tenant isolation | Single-tenant deployment for initial release |
| Batch processing queue | Out of scope; future integration |
| Knowledge graph visualization | Separate feature; future enhancement |
| Docker containerization | Phase 2 scope (separate charter) |
| Production deployment | Phase 2 scope (separate charter) |
| 13 advanced MCP tools | Backlog (see Section 18) |
| Plugin architecture implementation | Defer to Phase 2 (requires ecosystem planning) |

---

## 4. Scope

### 4.1 In Scope

#### 4.1.1 Core Features

| Feature | Description | MCP Tools Used |
|---------|-------------|----------------|
| File Upload | Drag-drop zone with file type validation | `convert_pdf`, `convert_docx`, `convert_xlsx`, `convert_pptx` |
| URL Input | URL validation with metadata preview | `convert_url` |
| Processing Status | Real-time progress via SSE with resilient reconnection | SSE transport |
| Results Viewer | Tabbed view: Markdown, HTML, JSON, Raw | `export_markdown`, `export_html`, `export_json` |
| Download | Export processed documents | All export tools |
| **History View** | View past processing jobs with pagination | PostgreSQL queries |
| **Result Persistence** | Store and retrieve past results | PostgreSQL storage |
| **Error Recovery** | Clear error states with retry actions | Error catalog |

#### 4.1.2 Supported Document Types

| Format | Extensions | Max Size | MCP Tool |
|--------|------------|----------|----------|
| PDF | .pdf | 100 MB | `convert_pdf` |
| Word | .doc, .docx | 50 MB | `convert_docx` |
| Excel | .xls, .xlsx | 50 MB | `convert_xlsx` |
| PowerPoint | .ppt, .pptx | 50 MB | `convert_pptx` |
| Images | .png, .jpg, .jpeg, .tiff | 25 MB | `convert_pdf` (image mode) |
| Web Pages | http://, https:// | N/A | `convert_url` |

#### 4.1.3 Supported Export Formats

| Format | Specification | Details |
|--------|---------------|---------|
| **Markdown** | GitHub Flavored Markdown (GFM) | Images as data URIs (base64), GFM table syntax, triple-backtick code blocks with language hints, YAML frontmatter with source URL and timestamp |
| **HTML** | Standalone with inline CSS | Tailwind CSS inlined, mobile-first responsive, respects `prefers-color-scheme` for dark mode, static only (no JavaScript) |
| **JSON** | Docling standard schema | Full AST hierarchy preserved, includes processing timestamp and source file info, 2-space indentation |
| **Raw** | Original DoclingDocument | Pretty-printed JSON of MCP response, for debugging/inspection |

**Download Naming Convention:**
```
{original_filename}_{YYYYMMDD_HHMMSS}_{format}.{ext}
Example: quarterly_report_20251211_143022_markdown.md
```

#### 4.1.4 UI Components (shadcn/ui)

| Component | Purpose | shadcn Component |
|-----------|---------|------------------|
| Upload Zone | File drag-drop area | Custom + `Card` |
| URL Input | URL entry with validation | `Input` + `Button` |
| Progress Indicator | Processing status | `Progress` |
| Results Tabs | Output format switching | `Tabs` |
| Toast Notifications | Success/error feedback | `Toast` |
| Dialog | Confirmation modals | `Dialog` |
| Skeleton | Loading states | `Skeleton` |
| **Data Table** | History view with pagination | `Table` |

### 4.2 Out of Scope

| Feature | Rationale | Future Phase |
|---------|-----------|--------------|
| Docker containerization | Separate charter | Phase 2 |
| Production deployment | Separate charter | Phase 2 |
| DNS/SSL configuration | Separate charter | Phase 2 |
| User authentication | Requires AD integration | Future |
| 13 advanced MCP tools | Backlog | See Section 18 |
| Plugin architecture | Requires ecosystem planning | Phase 2 |

---

## 5. Success Criteria

### 5.1 Functional Success Criteria

| ID | Criterion | Validation Method |
|----|-----------|-------------------|
| SC-F1 | User can upload PDF and receive Markdown output | Manual test |
| SC-F2 | User can upload Excel (.xls, .xlsx) and receive output | Manual test |
| SC-F3 | User can upload PowerPoint (.ppt, .pptx) and receive output | Manual test |
| SC-F4 | User can paste a URL and receive HTML output | Manual test |
| SC-F5 | Progress indicator updates in real-time during processing | SSE validation |
| SC-F6 | SSE reconnects automatically after network interruption | Resilience test |
| SC-F7 | User can switch between Markdown/HTML/JSON/Raw views | UI interaction test |
| SC-F8 | User can download processed output in selected format | Download validation |
| SC-F9 | Error states display error code + message + recovery action | Error injection test |
| SC-F10 | **User can view processing history with pagination** | History view test |
| SC-F11 | **User can re-download past results** | Persistence test |
| SC-F12 | **Health check endpoint reports all dependencies** | Health check test |

### 5.2 Non-Functional Success Criteria

| ID | Criterion | Target | Validation |
|----|-----------|--------|------------|
| SC-NF1 | Largest Contentful Paint (LCP) | < 2.5 seconds | Lighthouse |
| SC-NF2 | First Contentful Paint (FCP) | < 1.8 seconds | Lighthouse |
| SC-NF3 | Time to first progress update | < 500ms after submit | Timing measurement |
| SC-NF4 | UI responsive on tablet+ | >= 768px viewport | Manual test |
| SC-NF5 | Accessibility score | >= 90 (Lighthouse) | Lighthouse audit |
| SC-NF6 | Performance score | >= 80 (Lighthouse) | Lighthouse audit |
| SC-NF7 | No runtime errors in console | 0 errors | Browser dev tools |

**Performance Note**: Targets assume broadband connection (>10 Mbps). On 3G connections (<3 Mbps), page load time may exceed 10s. Test with Lighthouse throttling to verify mobile experience.

### 5.3 Resilience Success Criteria

| ID | Criterion | Validation |
|----|-----------|------------|
| SC-R1 | SSE reconnection succeeds within 30s of network drop | Network simulation |
| SC-R2 | Processing resumes after MCP transient failure (3 retries) | Fault injection |
| SC-R3 | Partial results displayed if some exports fail | Partial failure test |
| SC-R4 | Session survives browser refresh during processing | State recovery test |

---

## 6. Technical Architecture

### 6.1 Technology Stack

| Layer | Technology | Version | Rationale |
|-------|------------|---------|-----------|
| Framework | Next.js | 16.x (App Router) | Latest stable, Turbopack default |
| Runtime | Node.js | >= 20.9.0 (LTS) | Next.js 16 minimum requirement |
| UI Components | shadcn/ui | Latest | HX standard (hx-shadcn-server) |
| Styling | Tailwind CSS | 3.4.x | shadcn dependency |
| State Management | Zustand | 5.x | Minimal footprint, SSR-ready |
| Validation | Zod | 3.x | Runtime type safety |
| **Database ORM** | Prisma | 5.x | Type-safe PostgreSQL access |
| **Redis Client** | ioredis | 5.x | Session management |
| HTTP Client | Native fetch | - | Streaming SSE support |
| Icons | Lucide React | Latest | shadcn default |
| TypeScript | >= 5.1.0 | - | Next.js 16 minimum requirement |
| React | 19.2.x | - | Next.js 16 ships with React 19.2 |

### 6.2 High-Level Architecture

```mermaid
flowchart TB
    subgraph Users["Users"]
        U1[Knowledge Worker]
        U2[Data Engineer]
        U3[AI Developer]
    end

    subgraph Dev["hx-cc-server (192.168.10.224)"]
        subgraph UI["hx-docling-ui (Next.js 16 Dev Server)"]
            subgraph Presentation["Presentation Layer"]
                UZ[Upload Zone]
                URL[URL Input]
                RV[Results Viewer]
                HV[History View]
                EB[Error Boundary]
            end
            
            subgraph Application["Application Layer"]
                DS[Document Store<br/>Zustand]
                JM[Job Manager]
                MC[MCP Client]
                SSE[SSE Manager<br/>Reconnection Logic]
            end
            
            subgraph API["API Layer (Route Handlers)"]
                AU[/api/upload]
                AP[/api/process]
                AH[/api/history]
                AJ[/api/jobs/id]
                AS[/api/health]
            end
            
            subgraph Data["Data Layer"]
                PR[Prisma Client]
                RC[Redis Client]
            end
        end
        
        subgraph Storage["Persistent Storage"]
            FS[/data/docling-uploads/]
        end
    end

    subgraph HX["HX-Infrastructure"]
        MCP[hx-docling-mcp-server<br/>192.168.10.217:8000]
        PG[hx-postgres-server<br/>192.168.10.208:5432]
        RD[hx-redis-server<br/>192.168.10.209:6379]
        LLM[hx-litellm-server<br/>192.168.10.212:4000]
        OL3[hx-ollama3-server<br/>192.168.10.206:11434]
    end

    Users --> Dev
    Presentation --> Application
    Application --> API
    API --> Data
    Data --> FS
    API -->|MCP Protocol<br/>HTTP/SSE| MCP
    PR -->|SQL| PG
    RC -->|Redis Protocol| RD
    MCP --> LLM
    LLM --> OL3

    style Dev fill:#1a1a2e,stroke:#16213e,color:#eee
    style HX fill:#0f3460,stroke:#16213e,color:#eee
```

### 6.3 Component Architecture

```mermaid
flowchart TB
    subgraph Shell["Application Shell"]
        EB[ErrorBoundary]
        Header[Header Component]
        
        subgraph Main["Main Content"]
            subgraph Input["Input Section"]
                UploadZone[UploadZone.tsx<br/>Drag-drop files]
                UrlInput[UrlInput.tsx<br/>URL entry]
                FilePreview[FilePreview.tsx<br/>Selected file info]
                ProgressCard[ProgressCard.tsx<br/>Processing status]
            end
            
            subgraph Results["Results Section"]
                ResultsViewer[ResultsViewer.tsx<br/>Tabbed container]
                MarkdownView[MarkdownView.tsx]
                HtmlView[HtmlView.tsx]
                JsonView[JsonView.tsx]
                RawView[RawView.tsx]
                DownloadButton[DownloadButton.tsx]
                Skeleton[Skeleton loaders]
            end
            
            subgraph History["History Section"]
                HistoryView[HistoryView.tsx<br/>Past jobs table]
                JobDetail[JobDetail.tsx<br/>Individual job]
                Pagination[Pagination.tsx]
            end
        end
        
        Footer[Footer Component<br/>Version / Status]
    end

    EB --> Header
    Header --> Main
    Main --> Footer

    style Shell fill:#1a1a2e,stroke:#16213e,color:#eee
    style Input fill:#16213e,stroke:#0f3460,color:#eee
    style Results fill:#16213e,stroke:#0f3460,color:#eee
    style History fill:#16213e,stroke:#0f3460,color:#eee
```

#### 6.3.1 Input State Management (Addresses Minor 3.2)

Only one input type can be active at a time. The Zustand store enforces mutual exclusion:

```typescript
// stores/documentStore.ts
interface DocumentState {
  // Input state (mutually exclusive)
  file: File | null;
  url: string | null;
  activeInput: 'file' | 'url' | null;
  
  // Actions enforce mutual exclusion
  setFile: (file: File | null) => void;  // Clears URL, sets activeInput='file'
  setUrl: (url: string | null) => void;  // Clears file, sets activeInput='url'
  clearInputs: () => void;               // Clears both, sets activeInput=null
  
  // Processing lock
  isProcessing: boolean;
}

// Behavior:
// - If user drags file while URL is set → clear URL, set file
// - If URL input receives value while file set → clear file, set URL
// - During processing (isProcessing=true) → disable all input changes
// - All input components check isProcessing before allowing changes
```

#### 6.3.2 Results Viewer Behavior (Addresses Minor 3.4)

```typescript
// Results Viewer Tab Specification
interface ResultsViewerConfig {
  defaultTab: 'markdown';                           // Default selection
  tabOrder: ['markdown', 'html', 'json', 'raw'];   // Fixed order, not reorderable
  
  rendering: {
    strategy: 'eager';           // All tabs pre-rendered (no lazy loading)
    statePreservation: true;     // Tab content persists when switching
    sessionMemory: true;         // Last selected tab remembered in session
  };
  
  accessibility: {
    tabRole: 'tab';
    panelRole: 'tabpanel';
    ariaSelected: true;          // Active tab marked with aria-selected
    ariaControls: true;          // Tab links to panel via aria-controls
    keyboardNav: 'arrow-keys';   // Left/Right arrows switch tabs
    focusBehavior: 'tab-then-content'; // Tab key moves to content
  };
}
```

### 6.4 Directory Structure

```
hx-docling-ui/
├── src/
│   ├── app/                      # Next.js App Router
│   │   ├── layout.tsx            # Root layout with providers
│   │   ├── page.tsx              # Main application page
│   │   ├── history/
│   │   │   └── page.tsx          # History view page
│   │   ├── error.tsx             # Error boundary (App Router)
│   │   ├── loading.tsx           # Loading state
│   │   ├── api/
│   │   │   ├── upload/
│   │   │   │   └── route.ts      # File upload endpoint
│   │   │   ├── process/
│   │   │   │   └── route.ts      # MCP dispatch endpoint (SSE)
│   │   │   ├── history/
│   │   │   │   └── route.ts      # Job history endpoint (paginated)
│   │   │   ├── jobs/
│   │   │   │   └── [id]/
│   │   │   │       └── route.ts  # Individual job endpoint
│   │   │   └── health/
│   │   │       └── route.ts      # Health check endpoint
│   │   └── globals.css           # Global styles + Tailwind
│   │
│   ├── components/
│   │   ├── ui/                   # shadcn/ui components
│   │   ├── upload/
│   │   │   ├── UploadZone.tsx
│   │   │   ├── UrlInput.tsx
│   │   │   └── FilePreview.tsx
│   │   ├── processing/
│   │   │   ├── ProgressCard.tsx
│   │   │   ├── StatusBadge.tsx
│   │   │   └── ProgressStages.tsx
│   │   ├── results/
│   │   │   ├── ResultsViewer.tsx
│   │   │   ├── MarkdownView.tsx
│   │   │   ├── HtmlView.tsx
│   │   │   ├── JsonView.tsx
│   │   │   ├── RawView.tsx
│   │   │   ├── DownloadButton.tsx
│   │   │   └── ResultsSkeleton.tsx
│   │   ├── history/
│   │   │   ├── HistoryView.tsx
│   │   │   ├── JobRow.tsx
│   │   │   ├── JobDetail.tsx
│   │   │   └── Pagination.tsx
│   │   ├── layout/
│   │   │   ├── Header.tsx
│   │   │   ├── Footer.tsx
│   │   │   └── Container.tsx
│   │   └── error/
│   │       ├── ErrorDisplay.tsx
│   │       └── ErrorRecovery.tsx # Recovery action buttons
│   │
│   ├── lib/
│   │   ├── db/
│   │   │   └── prisma.ts         # Prisma client singleton
│   │   ├── redis/
│   │   │   └── client.ts         # Redis client singleton
│   │   ├── mcp/
│   │   │   ├── client.ts         # MCP client abstraction
│   │   │   ├── types.ts          # MCP protocol types
│   │   │   ├── tools.ts          # Tool definitions registry
│   │   │   ├── errors.ts         # Error catalog
│   │   │   └── recovery.ts       # Error recovery strategies
│   │   ├── sse/
│   │   │   ├── manager.ts        # SSE connection manager
│   │   │   └── reconnect.ts      # Reconnection logic
│   │   ├── validation/
│   │   │   ├── file.ts           # File validation schemas
│   │   │   └── url.ts            # URL validation schemas
│   │   └── utils/
│   │       ├── cn.ts             # Class name utility
│   │       ├── format.ts         # Formatting helpers
│   │       └── storage.ts        # File storage management
│   │
│   ├── stores/
│   │   ├── documentStore.ts      # Document state management
│   │   └── uiStore.ts            # UI state (modals, toasts)
│   │
│   ├── hooks/
│   │   ├── useUpload.ts
│   │   ├── useProcess.ts
│   │   ├── useSSE.ts             # SSE with reconnection
│   │   ├── useDownload.ts
│   │   ├── useHistory.ts
│   │   └── useKeyboardShortcuts.ts
│   │
│   └── types/
│       ├── document.ts
│       ├── processing.ts
│       ├── job.ts
│       └── errors.ts
│
├── prisma/
│   ├── schema.prisma             # Database schema
│   ├── seed.ts                   # Seed script
│   └── migrations/               # Migration files
│
├── scripts/
│   ├── cleanup-uploads.sh        # File cleanup cron script
│   └── cleanup-jobs.ts           # Database cleanup script
│
├── public/
│   └── (static assets)
│
├── .env.local
├── .env.development
├── .gitignore
├── next.config.ts
├── tailwind.config.ts
├── tsconfig.json
├── package.json
└── README.md
```

### 6.5 State Management

```mermaid
stateDiagram-v2
    [*] --> Idle: Initial State

    Idle --> FileSelected: User drops file
    Idle --> UrlEntered: User pastes URL
    
    FileSelected --> Uploading: Submit clicked
    UrlEntered --> Processing: Submit clicked
    
    Uploading --> Processing: Upload complete
    Uploading --> Error: Upload failed
    
    Processing --> Retry1: MCP error (transient)
    Retry1 --> Processing: Retry succeeds
    Retry1 --> Retry2: Still failing
    Retry2 --> Processing: Retry succeeds
    Retry2 --> Retry3: Still failing
    Retry3 --> Processing: Retry succeeds
    Retry3 --> Error: All retries exhausted
    
    Processing --> Complete: MCP returns result
    Processing --> PartialComplete: Some exports failed
    Processing --> Error: Fatal MCP error
    
    Complete --> Persisted: Results saved to DB
    PartialComplete --> Persisted: Partial results saved
    
    Persisted --> Idle: User clicks reset
    
    Error --> Idle: User clicks retry
    Error --> FileSelected: User selects new file
    Error --> UrlEntered: User enters new URL

    note right of Retry1
        Exponential backoff
        1s, 2s, 4s delays
    end note
    
    note right of PartialComplete
        Display available results
        Show which exports failed
    end note
```

### 6.6 Progress Stages

| Stage | Percent Range | Description | User Message |
|-------|---------------|-------------|--------------|
| `upload` | 0-10% | File upload in progress | "Uploading document..." |
| `parsing` | 10-40% | Document structure analysis | "Analyzing document structure..." |
| `conversion` | 40-80% | Granite Docling VLM processing | "Processing with AI..." |
| `export` | 80-95% | Generating MD/HTML/JSON | "Generating outputs..." |
| `saving` | 95-99% | Persisting to database | "Saving results..." |
| `complete` | 100% | Processing finished | "Complete!" |

### 6.7 Data Flow

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Next.js UI
    participant SSE as SSE Manager
    participant API as API Routes
    participant FS as File Storage
    participant PG as PostgreSQL
    participant RD as Redis
    participant MCP as hx-docling-mcp-server
    participant Store as Zustand Store

    Note over RD: Get/Create Session ID
    UI->>RD: Get session (cookie)
    RD-->>UI: sessionId

    alt File Upload Flow
        U->>UI: Drop PDF file
        UI->>Store: setFile(file)
        UI->>API: POST /api/upload
        API->>FS: Store at /data/docling-uploads/{uuid}
        API->>PG: Create Job record (PENDING)
        API-->>UI: { jobId, fileId }
    else URL Input Flow
        U->>UI: Paste URL
        UI->>Store: setUrl(url)
        UI->>API: POST /api/upload (URL mode)
        API->>PG: Create Job record (PENDING)
        API-->>UI: { jobId }
    end

    U->>UI: Click Process
    UI->>Store: startProcessing()
    UI->>SSE: Connect to /api/process (SSE)
    SSE->>API: POST /api/process
    API->>PG: Update Job (PROCESSING)
    
    API->>MCP: MCP tools/call (convert_*)
    
    loop SSE Progress Stream
        MCP-->>API: Progress event
        API-->>SSE: SSE: { stage, percent, message }
        SSE-->>UI: Emit progress
        UI->>Store: updateProgress(...)
    end
    
    alt Network Interruption
        Note over SSE: Connection lost
        SSE->>SSE: Reconnect (backoff: 1s, 2s, 4s, 8s)
        SSE->>API: Reconnect with jobId
        API-->>SSE: Resume stream from last state
    end
    
    MCP-->>API: Complete with DoclingDocument
    API->>MCP: MCP tools/call (export_markdown)
    API->>MCP: MCP tools/call (export_html)
    API->>MCP: MCP tools/call (export_json)
    
    API->>PG: Store Results (MD, HTML, JSON)
    API->>PG: Update Job (COMPLETE)
    API-->>SSE: SSE: complete with results
    SSE-->>UI: Emit complete
    
    UI->>Store: setResult({markdown, html, json})
    Store-->>UI: Re-render ResultsViewer
    UI-->>U: Display tabbed results
```

### 6.8 SSE Resilience Strategy (Addresses Critical 1.1)

```typescript
// lib/sse/manager.ts

interface SSEConfig {
  // Reconnection settings
  maxRetries: 10;
  backoffStrategy: 'exponential';
  backoffBase: 1000;        // 1 second
  backoffMax: 30000;        // 30 seconds max
  backoffMultiplier: 2;     // 1s → 2s → 4s → 8s → 16s → 30s
  
  // Grace period before giving up
  gracePeriod: 30000;       // 30 seconds total
  
  // Fallback
  fallbackToPolling: true;
  pollingInterval: 2000;    // 2 seconds
}

interface SSEState {
  connectionId: string;
  jobId: string;
  lastEventId: string | null;
  lastProgress: {
    stage: string;
    percent: number;
  };
  retryCount: number;
}

// Reconnection Flow:
// 1. Connection drops → save lastEventId and lastProgress
// 2. Wait backoff duration (exponential: 1s, 2s, 4s, 8s...)
// 3. Attempt reconnect with Last-Event-ID header
// 4. Server resumes from lastEventId OR sends full state if unknown
// 5. If max retries exceeded → fall back to polling
// 6. If gracePeriod exceeded → show error with manual retry button

// State Reconciliation:
// - On reconnect, server sends current job state
// - Client compares with local state
// - If server ahead → update local state
// - If server behind (shouldn't happen) → log warning, use server state

// User Experience:
// - During reconnection: Show "Reconnecting..." toast
// - After successful reconnect: Show "Reconnected" success toast
// - After fallback to polling: Show "Using backup connection" info toast
// - After all retries exhausted: Show error with "Retry" button
```

**Server-Side Support (API Route):**
```typescript
// app/api/process/route.ts

export async function POST(req: Request) {
  const lastEventId = req.headers.get('Last-Event-ID');
  const { jobId, sessionId } = await req.json();
  
  // If reconnecting, fetch current job state
  if (lastEventId) {
    const job = await prisma.job.findUnique({ where: { id: jobId } });
    if (job) {
      // Send current state immediately
      yield `id: ${generateEventId()}\ndata: ${JSON.stringify({
        type: 'state_sync',
        stage: job.currentStage,
        percent: job.currentPercent,
        message: job.currentMessage
      })}\n\n`;
    }
  }
  
  // Continue with normal SSE stream...
}
```

---

## 7. Persistent Storage

### 7.1 Storage Architecture

```mermaid
flowchart LR
    subgraph App["hx-docling-ui"]
        Prisma[Prisma Client]
        Redis[ioredis Client]
        FS[File Manager]
    end
    
    subgraph Storage["Persistent Storage"]
        PG[(hx-postgres-server<br/>192.168.10.208:5432)]
        RD[(hx-redis-server<br/>192.168.10.209:6379)]
        Disk[/data/docling-uploads/]
    end
    
    Prisma -->|Jobs, Results| PG
    Redis -->|Sessions| RD
    FS -->|Uploaded Files| Disk

    style App fill:#1a1a2e,stroke:#16213e,color:#eee
    style Storage fill:#16a34a,stroke:#16213e,color:#fff
```

### 7.2 What Gets Persisted

| Data | Storage Target | Purpose | Retention |
|------|----------------|---------|-----------|
| Processing results (MD, HTML, JSON) | hx-postgres-server | Re-download past conversions | 90 days |
| Job history/metadata | hx-postgres-server | View processing history, audit trail | 90 days |
| Uploaded files | `/data/docling-uploads/` | Re-process without re-upload | 30 days |
| User sessions | hx-redis-server | Track anonymous session activity | 24 hours |

### 7.3 Database Schema (Prisma)

```prisma
// prisma/schema.prisma

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Job {
  id          String    @id @default(uuid())
  sessionId   String    // Anonymous session from Redis
  status      JobStatus
  inputType   InputType
  
  // File metadata
  fileName    String?
  fileSize    Int?
  filePath    String?   // Path in /data/docling-uploads/
  mimeType    String?
  
  // URL metadata
  url         String?
  
  // Processing state (for SSE reconnection)
  currentStage   String?
  currentPercent Int?
  currentMessage String?
  
  // Timestamps
  createdAt   DateTime  @default(now())
  updatedAt   DateTime  @updatedAt
  completedAt DateTime?
  
  // Error tracking
  error       String?
  errorCode   String?
  retryCount  Int       @default(0)
  
  // Relations
  results     Result[]
  
  @@index([sessionId])
  @@index([createdAt])
  @@index([status])
}

model Result {
  id        String       @id @default(uuid())
  jobId     String
  job       Job          @relation(fields: [jobId], references: [id], onDelete: Cascade)
  format    ResultFormat
  content   String       @db.Text
  size      Int          // Content size in bytes
  createdAt DateTime     @default(now())
  
  @@index([jobId])
  @@index([format])
}

enum JobStatus {
  PENDING
  UPLOADING
  PROCESSING
  RETRY_1
  RETRY_2
  RETRY_3
  COMPLETE
  PARTIAL_COMPLETE
  ERROR
}

enum InputType {
  FILE
  URL
}

enum ResultFormat {
  MARKDOWN
  HTML
  JSON
  RAW
}
```

### 7.4 Session Management (Redis)

```typescript
// Session structure in Redis
interface Session {
  id: string;           // UUID
  createdAt: number;    // Unix timestamp
  lastActivity: number; // Unix timestamp
  jobCount: number;     // Number of jobs in session
  activeJobId: string | null; // Currently processing job
}

// Redis key pattern
// session:{sessionId} -> JSON string of Session
// TTL: 24 hours (86400 seconds)
```

#### 7.4.1 Session Edge Cases (Addresses Critical 1.2)

| Edge Case | Behavior | Implementation |
|-----------|----------|----------------|
| **Session expires during processing** | Job continues server-side. New session created on next request. User can view result in history (job has sessionId embedded). | Job.sessionId is immutable once set. Results persist regardless of session state. |
| **User closes browser mid-processing** | Job continues server-side until completion or timeout. Result persisted. | Server-side processing is fire-and-forget after SSE stream starts. Job completion is independent of client connection. |
| **User clears cookies** | New session created. Old history inaccessible from UI (but data remains in DB). | No automatic session recovery. User must contact admin if history needed. |
| **Session ID collision** | UUID v4 collision probability is negligible (1 in 2^122). | No special handling. Log error if detected. |
| **Multiple tabs in same session** | Allowed. Each tab can process independently. | Rate limiting applies per session (10 req/min). Tabs share quota. |
| **Database write fails mid-process** | Job marked as ERROR with error code E403. User can retry. | Transaction rollback. Temporary files retained for 1 hour for retry. |

**Session Timeout Cascade:**
```
Session TTL (24h) expires
    ↓
Session key deleted from Redis
    ↓
Jobs with that sessionId remain in PostgreSQL (90 days)
    ↓
Files remain in /data/docling-uploads/ (30 days)
    ↓
User cannot see history in UI (no session cookie)
    ↓
Data eventually cleaned up by retention policies
```

**Multi-Tab Conflict Resolution:**
```typescript
// Rate limiting is per-session, shared across tabs
// If Tab A and Tab B both try to process:
// - Both requests count against same 10 req/min quota
// - No additional locking needed
// - Both jobs can run in parallel on server
// - UI in each tab shows its own job progress
```

### 7.5 File Storage Structure

```
/data/docling-uploads/
├── 2025/
│   └── 12/
│       └── 11/
│           ├── {uuid}-document.pdf
│           ├── {uuid}-spreadsheet.xlsx
│           └── {uuid}-presentation.pptx
```

#### 7.5.1 File Storage Lifecycle (Addresses Critical 1.7)

| Aspect | Specification |
|--------|---------------|
| **Permissions** | Files created with `0640` (owner read/write, group read, no world access) |
| **Owner** | Application user (`node` or `docling-app`) |
| **Group** | `docling-files` (for backup access) |

**Cleanup Cron Job:**
```bash
# /etc/cron.d/docling-cleanup
# Run daily at 02:00 UTC
0 2 * * * docling-app /opt/hx-docling-ui/scripts/cleanup-uploads.sh >> /var/log/docling-cleanup.log 2>&1
```

**Cleanup Script (`scripts/cleanup-uploads.sh`):**
```bash
#!/bin/bash
# Delete files older than 30 days
find /data/docling-uploads -type f -mtime +30 -delete
# Delete empty directories
find /data/docling-uploads -type d -empty -delete
# Log completion
echo "$(date -Iseconds) Cleanup completed" >> /var/log/docling-cleanup.log
```

**Orphaned File Handling:**
- Weekly reconciliation script compares files on disk with Job.filePath in database
- Files without matching Job record are moved to `/data/docling-uploads/orphaned/`
- Orphaned files deleted after 7 days
- Alert triggered if orphan count > 100

**Storage Capacity:**
- Estimated: 30 days × 100 files/day × 50 MB avg = ~150 GB
- Minimum required: 500 GB for `/data` partition
- Alert threshold: 80% disk usage → email to admin
- Critical threshold: 95% → reject new uploads with E005 error

### 7.6 Data Retention Policy

| Data Type | Retention | Cleanup Method | Schedule |
|-----------|-----------|----------------|----------|
| Job records | 90 days | `scripts/cleanup-jobs.ts` | Daily 03:00 UTC |
| Result content | 90 days | Cascade delete with Job | Automatic |
| Uploaded files | 30 days | `scripts/cleanup-uploads.sh` | Daily 02:00 UTC |
| Redis sessions | 24 hours | Redis TTL auto-expire | Automatic |
| Orphaned files | 7 days | Reconciliation script | Weekly Sunday 04:00 UTC |

#### 7.6.1 Large Document Handling (Addresses Critical 1.6)

**Maximum Result Sizes:**
| Format | Max Size | Handling if Exceeded |
|--------|----------|---------------------|
| Markdown | 10 MB | Truncate with "... [truncated]" note |
| HTML | 15 MB | Truncate with "... [truncated]" note |
| JSON | 20 MB | Truncate arrays, preserve structure |
| Raw | 25 MB | Truncate with offset pointer |

**Compression Strategy:**
- Results stored as plain text (not compressed) for query efficiency
- Consider PostgreSQL TOAST for automatic compression of large text fields
- If result > 5 MB, log warning for monitoring

**History Pagination:**
```typescript
// /api/history endpoint
interface HistoryQuery {
  page: number;        // Default: 1
  pageSize: number;    // Default: 20, Max: 50
  sortBy: 'createdAt' | 'status';
  sortOrder: 'asc' | 'desc';
}

// Response includes pagination metadata
interface HistoryResponse {
  jobs: JobSummary[];  // Without full result content
  pagination: {
    page: number;
    pageSize: number;
    totalPages: number;
    totalCount: number;
    hasMore: boolean;
  };
}

// Job summary excludes large result content
// Full content fetched only when user views specific job
```

**Database Indexes for Performance:**
```sql
-- Already in Prisma schema, but documenting for clarity
CREATE INDEX idx_job_session_created ON "Job"("sessionId", "createdAt" DESC);
CREATE INDEX idx_job_status ON "Job"("status");
CREATE INDEX idx_result_job ON "Result"("jobId");
```

**Cleanup Script (`scripts/cleanup-jobs.ts`):**
```typescript
// scripts/cleanup-jobs.ts
import { prisma } from '../src/lib/db/prisma';

async function cleanupOldJobs() {
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - 90);
  
  const deleted = await prisma.job.deleteMany({
    where: {
      createdAt: { lt: cutoffDate }
    }
  });
  
  console.log(`Deleted ${deleted.count} jobs older than 90 days`);
}

cleanupOldJobs().catch(console.error);
```
## 8. Integration Requirements

### 8.1 MCP Server Integration

```mermaid
flowchart LR
    subgraph Dev["hx-cc-server (Dev)"]
        Client[MCP Client<br/>lib/mcp/client.ts]
    end

    subgraph MCP["hx-docling-mcp-server:8000"]
        HTTP[HTTP Transport<br/>/mcp]
        SSE[SSE Transport<br/>/mcp]
        Tools[19 MCP Tools]
    end

    Client -->|JSON-RPC 2.0| HTTP
    Client -->|Streaming| SSE
    HTTP --> Tools
    SSE --> Tools

    style Dev fill:#1a1a2e,stroke:#16213e,color:#eee
    style MCP fill:#0f3460,stroke:#16213e,color:#eee
```

| Aspect | Requirement |
|--------|-------------|
| Endpoint | `http://hx-docling-mcp-server.hx.dev.local:8000/mcp` |
| Protocol | JSON-RPC 2.0 over HTTP |
| Streaming | SSE for progress updates |
| Timeout | 300 seconds (large documents, see 8.1.2 for size-based) |
| Retry | 3 attempts with exponential backoff (1s, 2s, 4s) |
| Rate Limit | 10 requests/minute per session (enforced) |

#### 8.1.1 Rate Limiting & Quota Management (Addresses Major 2.2)

```typescript
// Rate Limiting Specification

interface RateLimitConfig {
  // Limit definition
  maxRequests: 10;           // Per minute
  windowMs: 60000;           // 1 minute sliding window
  scope: 'session';          // Per sessionId (from cookie)
  
  // Enforcement
  enforcementPoint: '/api/process';  // Rate limit on process route
  
  // On limit exceeded
  httpStatus: 429;           // Too Many Requests
  retryAfter: number;        // Seconds until reset (in header)
  
  // Response
  errorCode: 'E601';         // RATE_LIMIT_EXCEEDED
  userMessage: 'Rate limit reached. Please wait {seconds} seconds.';
}

// Implementation (middleware):
// - Use in-memory Map<sessionId, { count, windowStart }>
// - On each /api/process request:
//   1. Get sessionId from cookie
//   2. Check count within current window
//   3. If count >= 10: return 429 with Retry-After header
//   4. Else: increment count, process request
// - Window slides: reset count when windowStart + 60s < now

// Burst handling:
// - No burst allowance (strict limit)
// - Multiple tabs share same session quota
// - No queue depth limit (requests rejected, not queued)

// Monitoring:
// - Log all rate limit hits
// - Alert if same session hits limit 5+ times in 10 minutes
```

#### 8.1.2 Size-Based Timeout Adjustment

| File Size | Timeout |
|-----------|---------|
| < 10 MB | 60 seconds |
| 10-50 MB | 180 seconds |
| 50-100 MB | 300 seconds |
| > 100 MB | Rejected (E001) |

### 8.2 MCP Tools - Phase 1 Scope

**Phase 1 Tools (8 of 19):**

| Tool | File Types | Category |
|------|------------|----------|
| `convert_pdf` | .pdf | Conversion |
| `convert_docx` | .doc, .docx | Conversion |
| `convert_xlsx` | .xls, .xlsx | Conversion |
| `convert_pptx` | .ppt, .pptx | Conversion |
| `convert_url` | URLs | Conversion |
| `export_markdown` | - | Export |
| `export_html` | - | Export |
| `export_json` | - | Export |

**Backlog Tools (13):** See Section 18.

### 8.3 Environment Configuration

```env
# .env.development (hx-cc-server)
NODE_ENV=development

# MCP Server
DOCLING_MCP_URL=http://hx-docling-mcp-server.hx.dev.local:8000/mcp
DOCLING_MCP_TIMEOUT_SMALL=60000
DOCLING_MCP_TIMEOUT_MEDIUM=180000
DOCLING_MCP_TIMEOUT_LARGE=300000

# File Upload
MAX_FILE_SIZE_MB=100
ALLOWED_FILE_TYPES=.pdf,.docx,.doc,.pptx,.ppt,.xlsx,.xls,.png,.jpg,.jpeg,.tiff
TEMP_STORAGE_PATH=/tmp/docling-processing
PERSISTENT_STORAGE_PATH=/data/docling-uploads

# PostgreSQL (hx-postgres-server)
DATABASE_URL=postgresql://docling_user:${DB_PASSWORD}@hx-postgres-server.hx.dev.local:5432/docling_db

# Redis (hx-redis-server)
REDIS_URL=redis://hx-redis-server.hx.dev.local:6379/0

# Rate Limiting
RATE_LIMIT_MAX=10
RATE_LIMIT_WINDOW_MS=60000

# Application
NEXT_PUBLIC_APP_VERSION=1.0.0-dev
```

### 8.4 Infrastructure Dependencies

| Server | IP | Port | Purpose | Status |
|--------|-----|------|---------|--------|
| hx-cc-server | 192.168.10.224 | 3000 | Development server | ✅ Operational |
| hx-docling-mcp-server | 192.168.10.217 | 8000 | MCP document processing | ✅ Operational |
| hx-postgres-server | 192.168.10.208 | 5432 | Job & results persistence | ✅ Operational |
| hx-redis-server | 192.168.10.209 | 6379 | Session tracking | ✅ Operational |
| hx-litellm-server | 192.168.10.212 | 4000 | LLM routing (transitive) | ✅ Operational |
| hx-ollama3-server | 192.168.10.206 | 11434 | Model serving (transitive) | ✅ Operational |

### 8.5 Health Checks

| Dependency | Health Endpoint | Required | Check Frequency |
|------------|-----------------|----------|-----------------|
| Docling MCP | `http://hx-docling-mcp-server.hx.dev.local:8000/health` | Yes | On page load + every 30s |
| PostgreSQL | Prisma connection test | Yes | On startup + every 30s |
| Redis | `PING` command | Yes | On startup + every 30s |

### 8.6 MCP Error Recovery Strategy (Addresses Critical 1.3)

```mermaid
stateDiagram-v2
    [*] --> Processing: Start MCP call
    
    Processing --> Success: MCP returns result
    Processing --> TransientError: Timeout, 5xx, network error
    Processing --> FatalError: 4xx, validation error
    
    TransientError --> Retry1: Attempt 1
    Retry1 --> Processing: Wait 1s, retry
    Retry1 --> Retry2: Still failing
    
    Retry2 --> Processing: Wait 2s, retry
    Retry2 --> Retry3: Still failing
    
    Retry3 --> Processing: Wait 4s, retry
    Retry3 --> ExhaustedError: All retries failed
    
    Success --> ExportMarkdown: Convert complete
    ExportMarkdown --> ExportHtml: MD success
    ExportMarkdown --> PartialResult: MD failed
    
    ExportHtml --> ExportJson: HTML success
    ExportHtml --> PartialResult: HTML failed
    
    ExportJson --> Complete: JSON success
    ExportJson --> PartialResult: JSON failed
    
    PartialResult --> Complete: Save available results
    
    FatalError --> [*]: Show error, allow retry
    ExhaustedError --> [*]: Show error, allow retry
    Complete --> [*]: Show results
```

**Post-Failure Behavior:**

| Scenario | Job Status | UI Behavior | User Action |
|----------|------------|-------------|-------------|
| All 3 retries fail | `ERROR` | Show error with code + message | "Retry" button resets to `PENDING` |
| Convert succeeds, all exports fail | `ERROR` | Show "Conversion succeeded but export failed" | "Retry Export" button |
| Convert succeeds, some exports fail | `PARTIAL_COMPLETE` | Show available results, indicate missing | Download available, "Retry Missing" button |
| Timeout (300s) | `ERROR` with E301 | Show "Processing took too long" | "Retry" button, suggest smaller file |

**Partial Result Handling:**
```typescript
// If convert_* succeeds but export_* fails:
interface PartialResult {
  conversionSuccess: true;
  exports: {
    markdown: { success: boolean; content?: string; error?: string };
    html: { success: boolean; content?: string; error?: string };
    json: { success: boolean; content?: string; error?: string };
  };
}

// UI shows:
// - Green checkmark on successful exports
// - Red X with error message on failed exports
// - "Retry Failed Exports" button to re-run only failed exports
```

**Error-to-UI Mapping:**
```typescript
// lib/mcp/recovery.ts
export const MCPErrorRecovery: Record<string, ErrorRecovery> = {
  'TIMEOUT': {
    errorCode: 'E301',
    userMessage: 'Processing took too long. Large documents may require more time.',
    suggestedAction: 'Try with a smaller file or retry',
    retryable: true,
    retryDelay: 5000,
  },
  'MCP_UNAVAILABLE': {
    errorCode: 'E201',
    userMessage: 'Document processing service is temporarily unavailable.',
    suggestedAction: 'Please try again in a few minutes',
    retryable: true,
    retryDelay: 30000,
  },
  'TOOL_ERROR': {
    errorCode: 'E203',
    userMessage: 'An error occurred while processing your document.',
    suggestedAction: 'Try a different file format or check the file is not corrupted',
    retryable: true,
    retryDelay: 0,
  },
};
```

### 8.7 Health Check Implementation (Addresses Critical 1.5)

**Endpoint Specification:**
```typescript
// GET /api/health

interface HealthCheckResponse {
  status: 'healthy' | 'degraded' | 'unhealthy';
  timestamp: string;  // ISO 8601
  version: string;    // App version
  uptime: number;     // Seconds since start
  checks: {
    mcp: ServiceHealth;
    postgres: ServiceHealth;
    redis: ServiceHealth;
    fileStorage: ServiceHealth;
  };
}

interface ServiceHealth {
  status: 'ok' | 'error' | 'timeout';
  latency: number;    // Milliseconds
  message?: string;   // Error message if status !== 'ok'
  lastCheck: string;  // ISO 8601
}

// Status Logic:
// - healthy: All checks pass
// - degraded: Some non-critical checks fail (e.g., fileStorage)
// - unhealthy: Any critical check fails (mcp, postgres, redis)
```

**Implementation:**
```typescript
// app/api/health/route.ts

const HEALTH_CACHE_TTL = 30000; // 30 seconds
let cachedHealth: HealthCheckResponse | null = null;
let cacheTime: number = 0;

export async function GET() {
  // Return cached result if fresh
  if (cachedHealth && Date.now() - cacheTime < HEALTH_CACHE_TTL) {
    return Response.json(cachedHealth);
  }
  
  const checks = await Promise.all([
    checkMCP(),
    checkPostgres(),
    checkRedis(),
    checkFileStorage(),
  ]);
  
  const [mcp, postgres, redis, fileStorage] = checks;
  
  // Determine overall status
  const critical = [mcp, postgres, redis];
  const anyFailed = critical.some(c => c.status !== 'ok');
  const allFailed = critical.every(c => c.status !== 'ok');
  
  const status = allFailed ? 'unhealthy' : anyFailed ? 'degraded' : 'healthy';
  
  cachedHealth = {
    status,
    timestamp: new Date().toISOString(),
    version: process.env.NEXT_PUBLIC_APP_VERSION || 'unknown',
    uptime: process.uptime(),
    checks: { mcp, postgres, redis, fileStorage },
  };
  cacheTime = Date.now();
  
  const httpStatus = status === 'unhealthy' ? 503 : 200;
  return Response.json(cachedHealth, { status: httpStatus });
}

async function checkMCP(): Promise<ServiceHealth> {
  const start = Date.now();
  try {
    const res = await fetch(
      `${process.env.DOCLING_MCP_URL}/health`,
      { signal: AbortSignal.timeout(5000) }
    );
    return {
      status: res.ok ? 'ok' : 'error',
      latency: Date.now() - start,
      lastCheck: new Date().toISOString(),
    };
  } catch (e) {
    return {
      status: e.name === 'AbortError' ? 'timeout' : 'error',
      latency: Date.now() - start,
      message: e.message,
      lastCheck: new Date().toISOString(),
    };
  }
}

// Similar implementations for checkPostgres, checkRedis, checkFileStorage
```

---

## 9. Extensibility Framework

### 9.1 Plugin Architecture (Deferred to Phase 2)

> **Note**: Full plugin architecture implementation is deferred to Phase 2. This section documents the planned interface for future implementation.

**Rationale for Deferral:**
- Requires community feedback on plugin needs
- Version compatibility strategy needed
- Security sandbox considerations for third-party plugins
- Ecosystem planning (plugin registry, discovery, etc.)

**Planned Interface (Phase 2):**
```typescript
interface DoclingPlugin {
  id: string;
  name: string;
  version: string;
  
  onInit?: () => Promise<void>;
  onDestroy?: () => Promise<void>;
  
  beforeProcess?: (input: ProcessInput) => ProcessInput;
  afterProcess?: (result: ProcessResult) => ProcessResult;
  
  resultRenderers?: ResultRenderer[];
  toolbarActions?: ToolbarAction[];
}
```

### 9.2 Event System

```typescript
type DoclingEvent =
  | { type: 'FILE_SELECTED'; payload: { file: File } }
  | { type: 'URL_ENTERED'; payload: { url: string } }
  | { type: 'PROCESSING_STARTED'; payload: { jobId: string } }
  | { type: 'PROCESSING_PROGRESS'; payload: { jobId: string; stage: string; percent: number } }
  | { type: 'PROCESSING_COMPLETE'; payload: { jobId: string; result: ProcessResult } }
  | { type: 'PROCESSING_ERROR'; payload: { jobId: string; error: ErrorState } }
  | { type: 'SSE_RECONNECTED'; payload: { jobId: string; attempt: number } }
  | { type: 'JOB_PERSISTED'; payload: { jobId: string } }
  | { type: 'DOWNLOAD_REQUESTED'; payload: { format: string } };
```

---

## 10. User Experience Requirements

### 10.1 Design Principles

| Principle | Implementation |
|-----------|----------------|
| Progressive Disclosure | Show complexity only when needed |
| Immediate Feedback | Every action gets visual response within 100ms |
| Error Recovery | Clear error messages with actionable recovery paths |
| Accessibility | WCAG 2.1 AA compliance minimum |
| Resilience | Graceful degradation on connectivity issues |

### 10.2 Visual Design

| Aspect | Specification |
|--------|---------------|
| Theme | Dark mode primary (developer tool aesthetic) |
| Typography | System font stack (performance) |
| Color Palette | Neutral grays + accent for actions |
| Layout | Two-column: Input (40%) / Results (60%) |
| Responsive | Stacked single-column below 1024px |
| Contrast | WCAG 2.1 AA compliant (4.5:1 minimum) |

### 10.3 Browser Support

| Browser | Minimum Version | Notes |
|---------|-----------------|-------|
| Chrome | 111+ | Full support |
| Edge | 111+ | Full support |
| Firefox | 111+ | Full support |
| Safari | 16.4+ | SSE support required |

**Performance Note**: Targets assume broadband connection (>10 Mbps). On 3G connections (<3 Mbps), page load time may exceed 10s. Test with Lighthouse throttling to verify mobile experience.

### 10.4 Keyboard Shortcuts (Addresses Major 2.1)

| Shortcut | Action | Browser Conflict Check |
|----------|--------|------------------------|
| `Ctrl/Cmd + Enter` | Process selected file/URL | ✅ No conflict |
| `Ctrl/Cmd + Shift + D` | Download current results | Changed from Ctrl+D (bookmarks) |
| `Ctrl/Cmd + Shift + H` | Toggle history view | Changed from Ctrl+H (browser history) |
| `Ctrl/Cmd + L` | Focus URL input | ⚠️ Conflicts with address bar - intercept in app |
| `Ctrl/Cmd + U` | Open file picker | ⚠️ Conflicts with view source - intercept in app |
| `Escape` | Close dialogs, then reset form | Priority: Modal > Toast > Form |

**Focus Management Strategy:**
```typescript
// Focus order (Tab key):
// 1. Upload Zone (or URL Input if active)
// 2. Process Button
// 3. Results Tabs (if visible)
// 4. Active Tab Content
// 5. Download Button
// 6. History Toggle

// After processing completes:
// - Focus moves to Results Tabs
// - Announce "Processing complete" to screen readers

// Modal focus trap:
// - Tab cycles within modal
// - Escape closes modal, returns focus to trigger element

// Escape key priority:
// 1. If modal open → close modal
// 2. Else if toast visible → dismiss toast
// 3. Else if processing → show "Cancel?" confirmation
// 4. Else → reset form to initial state
```

**Mobile/Tablet Considerations:**
- No keyboard shortcuts on touch devices
- Long-press on Download button → show format options
- Swipe left/right on Results to switch tabs
- Pull-to-refresh on History view

### 10.5 Empty States

| Location | Message |
|----------|---------|
| Results Panel | "Upload a document or enter a URL to begin" |
| Processing | Skeleton loaders with pulsing animation |
| No Results | "No content extracted. Try a different document." |
| History Empty | "No processing history yet. Process your first document!" |
| History Loading | Skeleton rows with pulsing animation |

---

## 11. Security & Access Control

### 11.1 Security Model

| Concern | Approach |
|---------|----------|
| Authentication | None (anonymous sessions via Redis) |
| Session Tracking | UUID cookie, 24-hour TTL |
| File Uploads | Server-side validation, persistent storage |
| Database | Parameterized queries via Prisma |
| Network Access | hx.dev.local internal network only |
| Rate Limiting | 10 requests/minute per session (enforced) |

### 11.2 Input Validation

```typescript
const fileSchema = z.object({
  name: z.string().min(1).refine(
    (name) => ALLOWED_EXTENSIONS.some(ext => name.toLowerCase().endsWith(ext)),
    { message: 'Unsupported file extension' }
  ),
  size: z.number().max(100 * 1024 * 1024),
  type: z.enum([
    'application/pdf',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'application/msword',
    'application/vnd.openxmlformats-officedocument.presentationml.presentation',
    'application/vnd.ms-powerpoint',
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    'application/vnd.ms-excel',
    'image/png',
    'image/jpeg',
    'image/tiff',
  ]),
});

const ALLOWED_EXTENSIONS = [
  '.pdf', 
  '.doc', '.docx', 
  '.ppt', '.pptx', 
  '.xls', '.xlsx', 
  '.png', '.jpg', '.jpeg', '.tiff'
];
```

### 11.3 URL Input Security (Addresses Major 2.5)

```typescript
// lib/validation/url.ts

const urlSchema = z.string()
  .url({ message: 'Invalid URL format' })
  .max(2048, { message: 'URL too long (max 2048 characters)' })
  .refine(url => {
    const parsed = new URL(url);
    
    // Protocol validation: HTTP/HTTPS only
    if (!['http:', 'https:'].includes(parsed.protocol)) {
      return false;
    }
    
    // SSRF Prevention: Block private/internal IPs
    const hostname = parsed.hostname.toLowerCase();
    
    // Block localhost
    if (hostname === 'localhost' || hostname === '127.0.0.1') {
      return false;
    }
    
    // Block private IP ranges (RFC 1918)
    const ipv4Pattern = /^(\d{1,3}\.){3}\d{1,3}$/;
    if (ipv4Pattern.test(hostname)) {
      const parts = hostname.split('.').map(Number);
      // 10.0.0.0/8
      if (parts[0] === 10) return false;
      // 172.16.0.0/12
      if (parts[0] === 172 && parts[1] >= 16 && parts[1] <= 31) return false;
      // 192.168.0.0/16
      if (parts[0] === 192 && parts[1] === 168) return false;
      // 169.254.0.0/16 (link-local)
      if (parts[0] === 169 && parts[1] === 254) return false;
    }
    
    // Block internal HX domains (prevent accessing internal services)
    if (hostname.endsWith('.hx.dev.local')) {
      return false;
    }
    
    return true;
  }, { message: 'URL not allowed (internal or private address)' });

// URL Preview Specification
interface UrlPreview {
  timeout: 5000;                    // 5 seconds
  maxRedirects: 3;                  // Follow up to 3 redirects
  userAgent: 'hx-docling-ui/1.0';   // Identify as bot
  
  // Extract from response:
  // 1. <title> tag content
  // 2. og:title meta tag
  // 3. First 150 characters of body text (fallback)
}

// Error Handling
// E101 (INVALID_URL): Malformed URL, blocked domain
// E102 (URL_UNREACHABLE): DNS failure, connection refused, 4xx/5xx
// E103 (URL_TIMEOUT): No response within 30 seconds (for processing)
```

---

## 12. Development Environment

### 12.1 Development Server

| Aspect | Value |
|--------|-------|
| **Server** | hx-cc-server.hx.dev.local |
| **IP Address** | 192.168.10.224 |
| **Runtime** | Node.js 20.x (native, NO Docker) |
| **Dev Server** | Next.js dev server (`npm run dev`) |
| **Port** | 3000 |
| **Access URL** | `http://hx-cc-server.hx.dev.local:3000` |

### 12.2 Prerequisites

| Prerequisite | Version | Verification |
|--------------|---------|--------------|
| Node.js | >= 20.9.0 | `node --version` |
| npm | >= 10.x | `npm --version` |
| Git | Latest | `git --version` |
| PostgreSQL access | - | `psql -h hx-postgres-server.hx.dev.local` |
| Redis access | - | `redis-cli -h hx-redis-server.hx.dev.local ping` |
| MCP server access | - | `curl http://hx-docling-mcp-server.hx.dev.local:8000/health` |

### 12.3 Setup Commands

```bash
# On hx-cc-server (192.168.10.224)

# 1. Navigate to project directory
cd /home/agent0/hx-docling-ui

# 2. Install dependencies
npm install

# 3. Create environment file
cp .env.example .env.development

# 4. Generate Prisma client
npx prisma generate

# 5. Run database migrations
npx prisma migrate dev --name initial_schema

# 6. Seed database (optional, for testing)
npx prisma db seed

# 7. Start development server
npm run dev
```

#### 12.3.1 Prisma Client Singleton (Addresses Minor 3.1)

```typescript
// src/lib/db/prisma.ts

import { PrismaClient } from '@prisma/client';

// Prevent multiple instances during hot reload in development
const globalForPrisma = globalThis as unknown as {
  prisma: PrismaClient | undefined;
};

export const prisma =
  globalForPrisma.prisma ??
  new PrismaClient({
    log: process.env.NODE_ENV === 'development' 
      ? ['query', 'error', 'warn'] 
      : ['error'],
  });

if (process.env.NODE_ENV !== 'production') {
  globalForPrisma.prisma = prisma;
}

export default prisma;
```

#### 12.3.2 Type Safety Strategy (Addresses Minor 3.7)

```typescript
// Prisma generates types in node_modules/.prisma/client/
// Import types directly from @prisma/client:

import { Job, Result, JobStatus, ResultFormat } from '@prisma/client';

// Workflow after schema changes:
// 1. Edit prisma/schema.prisma
// 2. Run: npx prisma migrate dev --name {description}
// 3. Prisma auto-regenerates types
// 4. TypeScript picks up new types automatically
// 5. Commit migration file, NOT node_modules/.prisma/

// Zod + Prisma coordination:
// - Prisma types for database operations (compile-time)
// - Zod schemas for API input validation (runtime)
// - Keep both in sync manually when schema changes
```

### 12.4 Project Location

| Path | Description |
|------|-------------|
| `/home/agent0/hx-docling-ui/` | Project root |
| `/data/docling-uploads/` | Persistent file storage |
| `/tmp/docling-processing/` | Temporary upload staging |

### 12.5 Database Management Strategy (Addresses Critical 1.4)

#### Migration Naming Convention
```
YYYYMMDD_HHMMSS_description
Examples:
- 20251211_143000_initial_schema
- 20251212_091500_add_retry_count
- 20251215_160000_add_result_compression
```

#### Migration Workflow
```bash
# Create new migration (development)
npx prisma migrate dev --name add_new_column

# Apply migrations without creating new ones (CI/staging)
npx prisma migrate deploy

# Reset database (CAUTION: deletes all data)
npx prisma migrate reset

# View migration status
npx prisma migrate status
```

#### Rollback Procedure
```bash
# Prisma doesn't have built-in rollback
# Manual rollback procedure:

# 1. Identify the migration to rollback
ls prisma/migrations/

# 2. Manually write reverse SQL
psql -h hx-postgres-server.hx.dev.local -d docling_db -f rollback.sql

# 3. Delete the migration folder
rm -rf prisma/migrations/20251212_091500_add_retry_count

# 4. Regenerate Prisma client
npx prisma generate

# 5. Document the rollback in changelog
```

#### Seed Script
```typescript
// prisma/seed.ts

import { PrismaClient } from '@prisma/client';

const prisma = new PrismaClient();

async function main() {
  // Create test session
  const testSessionId = 'test-session-00000000-0000-0000-0000-000000000000';
  
  // Create sample completed job
  await prisma.job.create({
    data: {
      id: 'test-job-00000000-0000-0000-0000-000000000001',
      sessionId: testSessionId,
      status: 'COMPLETE',
      inputType: 'FILE',
      fileName: 'sample.pdf',
      fileSize: 1024000,
      filePath: '/data/docling-uploads/2025/12/11/sample.pdf',
      mimeType: 'application/pdf',
      completedAt: new Date(),
      results: {
        create: [
          {
            format: 'MARKDOWN',
            content: '# Sample Document\n\nThis is a test.',
            size: 42,
          },
          {
            format: 'HTML',
            content: '<h1>Sample Document</h1><p>This is a test.</p>',
            size: 52,
          },
        ],
      },
    },
  });
  
  console.log('Seed data created');
}

main()
  .catch(console.error)
  .finally(() => prisma.$disconnect());
```

```json
// package.json (add)
{
  "prisma": {
    "seed": "ts-node --compiler-options {\"module\":\"CommonJS\"} prisma/seed.ts"
  }
}
```

#### Test Database Strategy
```bash
# Use separate database for tests
# .env.test
DATABASE_URL=postgresql://docling_user:password@hx-postgres-server.hx.dev.local:5432/docling_db_test

# Reset test database before each test run
npx prisma migrate reset --force --skip-seed

# Or use Prisma's test utilities
# See: https://www.prisma.io/docs/guides/testing
```

---

## 13. Quality Gates

### 13.1 Code Quality Gates

| Gate | Threshold | Tool |
|------|-----------|------|
| TypeScript Errors | 0 | `tsc --noEmit` |
| ESLint Errors | 0 | `eslint` |
| ESLint Warnings | < 10 | `eslint` |
| Build Success | Required | `npm run build` |
| Prisma Generate | Required | `npx prisma generate` |

### 13.2 Test Gates (Addresses Major 2.4)

| Gate | Threshold | Tool |
|------|-----------|------|
| Unit Test Pass | 100% | Vitest |
| Unit Test Coverage (Lines) | >= 80% | Vitest |
| Unit Test Coverage (Branches) | >= 75% | Vitest |
| Component Render | All 15+ components | React Testing Library |
| API Route Tests | All routes | Vitest |
| Store Tests | All state mutations | Vitest |
| E2E Critical Path | Upload → Process → View → History | Playwright |
| MCP Integration | Real server test | Integration test suite |
| Database Integration | Real PostgreSQL | Integration test suite |

#### Component Testing Strategy

**Critical Components (100% coverage required):**
| Component | Test Focus |
|-----------|------------|
| UploadZone | File selection, drag-drop, validation errors |
| UrlInput | URL validation, SSRF rejection, preview |
| ProgressCard | SSE progress updates, state transitions, reconnection |
| ResultsViewer | Tab switching, content rendering, download |
| HistoryView | Pagination, job filtering, re-download |
| ErrorDisplay | Error code rendering, recovery actions |

**Testing Patterns:**
```typescript
// Component testing with React Testing Library
// Focus on user behavior, not implementation

// Example: UploadZone test
import { render, screen, fireEvent } from '@testing-library/react';
import { UploadZone } from './UploadZone';

describe('UploadZone', () => {
  it('accepts valid PDF file', async () => {
    render(<UploadZone />);
    
    const file = new File(['content'], 'test.pdf', { type: 'application/pdf' });
    const dropzone = screen.getByTestId('upload-dropzone');
    
    fireEvent.drop(dropzone, { dataTransfer: { files: [file] } });
    
    expect(screen.getByText('test.pdf')).toBeInTheDocument();
  });
  
  it('rejects file over 100MB', async () => {
    render(<UploadZone />);
    
    // Create mock large file
    const largeFile = new File(['x'.repeat(101 * 1024 * 1024)], 'large.pdf', { 
      type: 'application/pdf' 
    });
    const dropzone = screen.getByTestId('upload-dropzone');
    
    fireEvent.drop(dropzone, { dataTransfer: { files: [largeFile] } });
    
    expect(screen.getByText(/file must be under 100 MB/i)).toBeInTheDocument();
  });
});
```

**E2E Testing (Playwright):**
```typescript
// test/e2e/critical-path.spec.ts

import { test, expect } from '@playwright/test';

test.describe('Critical Path', () => {
  test('upload PDF → view markdown → download', async ({ page }) => {
    // Precondition: Real MCP server running
    await page.goto('http://hx-cc-server.hx.dev.local:3000');
    
    // Upload file
    const fileInput = page.locator('input[type="file"]');
    await fileInput.setInputFiles('test/fixtures/sample.pdf');
    
    // Start processing
    await page.click('button:has-text("Process")');
    
    // Wait for completion (up to 60s for large files)
    await expect(page.locator('[data-testid="progress-complete"]'))
      .toBeVisible({ timeout: 60000 });
    
    // Verify markdown tab has content
    await page.click('button:has-text("Markdown")');
    await expect(page.locator('[data-testid="markdown-content"]'))
      .toContainText('Sample');
    
    // Download and verify
    const [download] = await Promise.all([
      page.waitForEvent('download'),
      page.click('button:has-text("Download")'),
    ]);
    
    expect(download.suggestedFilename()).toMatch(/\.md$/);
  });
});
```

**Accessibility Testing:**
```typescript
// Include axe-core in component tests
import { axe, toHaveNoViolations } from 'jest-axe';

expect.extend(toHaveNoViolations);

it('UploadZone has no accessibility violations', async () => {
  const { container } = render(<UploadZone />);
  const results = await axe(container);
  expect(results).toHaveNoViolations();
});

// Manual checklist (verify before release):
// [ ] All interactive elements focusable with Tab
// [ ] Focus visible on all elements
// [ ] Color contrast >= 4.5:1
// [ ] Screen reader announces all state changes
// [ ] Form errors associated with inputs
// [ ] Images have alt text
```

#### Store Testing (Addresses Minor 3.8)

```typescript
// stores/documentStore.test.ts

import { useDocumentStore } from './documentStore';

describe('documentStore', () => {
  beforeEach(() => {
    // Reset store between tests
    useDocumentStore.setState({
      file: null,
      url: null,
      activeInput: null,
      isProcessing: false,
    });
  });
  
  it('setFile clears URL and sets activeInput', () => {
    const store = useDocumentStore.getState();
    const mockFile = new File([''], 'test.pdf');
    
    // First set URL
    store.setUrl('https://example.com');
    expect(useDocumentStore.getState().url).toBe('https://example.com');
    
    // Then set file - should clear URL
    store.setFile(mockFile);
    
    const state = useDocumentStore.getState();
    expect(state.file).toBe(mockFile);
    expect(state.url).toBeNull();
    expect(state.activeInput).toBe('file');
  });
  
  it('prevents input changes during processing', () => {
    const store = useDocumentStore.getState();
    const mockFile = new File([''], 'test.pdf');
    
    // Start processing
    store.setFile(mockFile);
    store.startProcessing();
    
    // Attempt to change input
    store.setUrl('https://example.com');
    
    // Should not change
    expect(useDocumentStore.getState().url).toBeNull();
    expect(useDocumentStore.getState().file).toBe(mockFile);
  });
});
```

### 13.3 Logging Strategy

| Log Type | Destination | Level | Format |
|----------|-------------|-------|--------|
| Application logs | Console (stdout) | info | JSON |
| Error logs | Console (stderr) | error | JSON |
| Database queries | Console | debug | Prisma format |
| Health checks | Console | info | JSON |
| Rate limit hits | Console | warn | JSON |

**Log Format:**
```typescript
// Structured logging format
interface LogEntry {
  timestamp: string;      // ISO 8601
  level: 'debug' | 'info' | 'warn' | 'error';
  message: string;
  context?: {
    jobId?: string;
    sessionId?: string;
    errorCode?: string;
    latency?: number;
    [key: string]: unknown;
  };
}

// Example log entries:
// {"timestamp":"2025-12-11T14:30:00Z","level":"info","message":"Job started","context":{"jobId":"abc-123","sessionId":"session-456"}}
// {"timestamp":"2025-12-11T14:30:05Z","level":"error","message":"MCP timeout","context":{"jobId":"abc-123","errorCode":"E301","latency":300000}}
```

### 13.4 Performance Testing (Addresses Critical 1.8)

**Load Test Scenarios:**

| Scenario | Description | Target |
|----------|-------------|--------|
| Single User PDF | Upload 5MB PDF → view results | LCP < 2.5s, processing < 60s |
| Single User Large | Upload 95MB PDF | Processing < 300s, no timeout |
| 5 Concurrent Users | Each uploads different document | All complete without error |
| Slow Network (3G) | Upload 1MB PDF with throttling | Page loads < 10s, completes |
| SSE Resilience | Interrupt network mid-process | Reconnects, completes |

**Measurement Tools:**
- Lighthouse (accessibility + performance scores)
- Chrome DevTools Performance tab
- Custom timing instrumentation (`performance.mark()`)
- Playwright for automated load tests

**Performance Metrics to Track:**
```typescript
// Custom performance marks
performance.mark('upload-start');
// ... upload logic
performance.mark('upload-end');
performance.measure('upload-duration', 'upload-start', 'upload-end');

// Key metrics:
// - FCP (First Contentful Paint): < 1.8s
// - LCP (Largest Contentful Paint): < 2.5s
// - TTI (Time to Interactive): < 3.5s
// - CLS (Cumulative Layout Shift): < 0.1
// - Time to first SSE event: < 500ms after submit
```

### 13.5 Observability & Monitoring (Addresses Critical 1.9)

**Application Metrics:**

| Metric | Type | Description |
|--------|------|-------------|
| `jobs_total` | Counter | Total jobs processed (by status) |
| `jobs_duration_seconds` | Histogram | Processing time by document type |
| `uploads_total` | Counter | Total uploads (by file type) |
| `uploads_size_bytes` | Histogram | Upload file sizes |
| `errors_total` | Counter | Errors by code |
| `active_sessions` | Gauge | Current active sessions |
| `sse_reconnections_total` | Counter | SSE reconnection attempts |

**Health Metrics:**

| Metric | Type | Description |
|--------|------|-------------|
| `health_check_duration_seconds` | Histogram | Health check latency by service |
| `health_check_status` | Gauge | Current status (1=ok, 0=error) |
| `db_connections_active` | Gauge | Active database connections |
| `disk_usage_bytes` | Gauge | /data partition usage |

**Alerting Rules:**

| Condition | Severity | Action |
|-----------|----------|--------|
| MCP unavailable > 1 minute | Critical | Page on-call |
| Error rate > 5% (5 min window) | High | Slack alert |
| Processing time > 5 minutes | Medium | Log investigation |
| Disk usage > 80% | High | Slack alert |
| Disk usage > 95% | Critical | Page on-call, reject uploads |
| Rate limit hits > 50/hour | Low | Log for analysis |

**Logging Infrastructure (Phase 1):**
- Logs to stdout/stderr (container-friendly)
- JSON format for parseability
- Centralized aggregation deferred to Phase 2

**Dashboard Metrics (Phase 1):**
- `/api/health` endpoint provides current status
- `/api/metrics` endpoint (future) for Prometheus scraping
- Manual log analysis for debugging

---

## 14. Constraints & Assumptions

### 14.1 Constraints

| ID | Constraint | Impact |
|----|------------|--------|
| C-1 | No external network dependencies | All API calls to hx.dev.local |
| C-2 | Must use shadcn/ui components | Design system consistency |
| C-3 | Anonymous sessions (no auth) | Session-based history only |
| C-4 | Max file size 100MB | MCP server limit |
| C-5 | SSE required for progress | Browser compatibility |
| C-6 | Node.js >= 20.9.0 | Next.js 16 requirement |
| C-7 | Development on hx-cc-server only | Phase 1 environment |
| C-8 | NO Docker | Phase 1 is bare metal only |
| C-9 | Rate limit: 10 req/min | Prevents abuse |
| C-10 | Result size limits | See Section 7.6.1 |

### 14.2 Assumptions

| ID | Assumption | Risk if False |
|----|------------|---------------|
| A-1 | hx-docling-mcp-server operational | Core functionality blocked |
| A-2 | hx-postgres-server accessible | Persistence blocked |
| A-3 | hx-redis-server accessible | Session tracking blocked |
| A-4 | Network latency < 50ms | UX degradation |
| A-5 | Node.js 20.x on hx-cc-server | Setup required |
| A-6 | /data partition has >= 500GB | File storage blocked |
| A-7 | MCP server returns within 300s | Timeout errors |

---

## 15. Risks & Mitigations

| ID | Risk | Likelihood | Impact | Mitigation |
|----|------|------------|--------|------------|
| R-1 | MCP server unavailable | Low | High | Health check, graceful degradation, retry |
| R-2 | Database connection failure | Low | High | Connection pool, retry, error UI |
| R-3 | Redis unavailable | Low | Medium | Fallback to cookie-only session |
| R-4 | Large file processing timeout | Medium | Medium | Size-based timeout, progress feedback |
| R-5 | SSE connection drops | Medium | Low | Auto-reconnect with backoff |
| R-6 | Disk space exhaustion | Low | High | Retention policy, monitoring, alerts |
| R-7 | Rate limit abuse | Low | Low | Enforce limits, log for analysis |
| R-8 | Partial export failure | Medium | Medium | Show available results, retry option |

---

## 16. Implementation Plan

### 16.1 Sprint Overview

```mermaid
gantt
    title Phase 1: Development on hx-cc-server
    dateFormat  YYYY-MM-DD
    section Setup
    Project Scaffold & Prisma Setup    :p1, 2025-12-12, 1d
    Database & Redis Integration       :p2, after p1, 1d
    section Upload
    Upload Component & File Storage    :p3, after p2, 1d
    URL Input Component                :p4, after p3, 1d
    section Processing
    MCP Client (8 tools) & SSE         :p5, after p4, 1d
    Integration Checkpoint             :milestone, m1, after p5, 0d
    section Results
    Results Viewer                     :p6, after m1, 1d
    History View                       :p7, after p6, 1d
    section Polish
    Testing & Documentation            :p8, after p7, 2d
    Phase 1 Complete                   :milestone, m2, after p8, 0d
```

### 16.2 Sprint Details

| Sprint | Deliverable | Duration | Key Files |
|--------|-------------|----------|-----------|
| 1.1 | Project scaffold, Next.js 16, shadcn, Prisma setup | 1 session | `package.json`, `prisma/schema.prisma` |
| 1.2 | Database connection, Redis setup, session tracking, health endpoint | 1 session | `lib/db/prisma.ts`, `lib/redis/client.ts`, `/api/health` |
| 1.3 | Upload component, file validation, persistent storage | 1 session | `UploadZone.tsx`, `/api/upload/route.ts` |
| 1.4 | URL input component with security validation | 1 session | `UrlInput.tsx`, `lib/validation/url.ts` |
| 1.5 | MCP client (8 tools), SSE with reconnection, error recovery | 1 session | `lib/mcp/client.ts`, `lib/sse/manager.ts`, `/api/process/route.ts` |
| **Checkpoint** | Integration validation with real servers | - | Manual verification |
| 1.6 | Results viewer (tabs, renderers, skeleton, download) | 1 session | `ResultsViewer.tsx`, views |
| 1.7 | History view (pagination, re-download) | 1 session | `HistoryView.tsx`, `/api/history/route.ts` |
| 1.8 | Testing, monitoring setup, documentation | 2 sessions | Tests, scripts, README |

**Estimated Total**: 9-10 Claude Code sessions

---

## 17. Acceptance Criteria

### 17.1 Final Acceptance Criteria

| ID | Criterion | Verification |
|----|-----------|--------------|
| AC-1 | User can drag-drop PDF file | Live demo |
| AC-2 | User can drag-drop Excel (.xls, .xlsx) | Live demo |
| AC-3 | User can drag-drop PowerPoint (.ppt, .pptx) | Live demo |
| AC-4 | User can paste URL (with SSRF protection) | Live demo |
| AC-5 | Progress updates display with stages | Live demo |
| AC-6 | SSE reconnects after network interruption | Resilience test |
| AC-7 | Markdown result renders correctly | Visual inspection |
| AC-8 | HTML result renders correctly | Visual inspection |
| AC-9 | JSON result displays formatted | Visual inspection |
| AC-10 | User can download results with proper filename | File download test |
| AC-11 | Error states display code + message + recovery action | Error injection |
| AC-12 | Partial results shown when some exports fail | Partial failure test |
| AC-13 | Processing results persist to PostgreSQL | Database query |
| AC-14 | History view shows past jobs with pagination | Live demo |
| AC-15 | User can re-download past results | Live demo |
| AC-16 | Session tracking works via Redis | Redis inspection |
| AC-17 | Health endpoint reports all dependencies | Health check test |
| AC-18 | Rate limiting enforced (10 req/min) | Rate limit test |
| AC-19 | Application runs at port 3000 | Manual verification |
| AC-20 | `npm run build` succeeds | Build verification |

---

## 18. Backlog

### 18.1 Deferred MCP Tools

The following 13 MCP tools are documented for future implementation:

| Tool | Description | Complexity | Priority |
|------|-------------|------------|----------|
| `generate_title` | Auto-generate document title | Low | Medium |
| `generate_toc` | Generate table of contents | Medium | Medium |
| `generate_sections` | Extract document sections | Medium | Low |
| `generate_headings` | Extract heading hierarchy | Low | Low |
| `generate_paragraphs` | Extract paragraphs | Low | Low |
| `generate_lists` | Extract lists | Low | Low |
| `generate_tables` | Extract tables as structured data | Medium | Medium |
| `generate_images` | Extract embedded images | Medium | Low |
| `generate_code_blocks` | Extract code blocks | Low | Medium |
| `generate_references` | Extract references/citations | Medium | Low |
| `generate_knowledge_graph` | Entity extraction to graph | High | High |
| `split_document` | Split into sections | Medium | Medium |
| `merge_documents` | Merge multiple documents | High | Low |

### 18.2 Future Features (Not Prioritized)

- User authentication (AD/Kerberos integration)
- Multi-tenant isolation
- Batch processing queue
- Knowledge graph visualization
- Document comparison
- Collaborative editing
- Plugin architecture implementation (see Section 9.1)

---

## 19. Related Documentation

### 19.1 HX-Infrastructure References

| Document | Location |
|----------|----------|
| Node Inventory | `/home/agent0/HX-Infrastructure/inventory/nodes.md` |
| Docling MCP Service | `services/operational/hx-docling-mcp-server/` |
| PostgreSQL Server | `nodes/hx-postgres-server/` |
| Redis Server | `nodes/hx-redis-server/` |
| shadcn MCP Server | `nodes/hx-shadcn-server/` |

### 19.2 External References

| Resource | URL |
|----------|-----|
| Next.js 16 Documentation | https://nextjs.org/docs |
| Prisma Documentation | https://www.prisma.io/docs |
| shadcn/ui Components | https://ui.shadcn.com/docs |
| MCP Protocol | https://modelcontextprotocol.io |

---

## 20. Appendices

### Appendix A: Error Catalog with Recovery (Addresses Minor 3.5)

```typescript
// lib/mcp/errors.ts

export enum ErrorCode {
  // File errors (E0xx)
  FILE_TOO_LARGE = 'E001',
  UNSUPPORTED_FORMAT = 'E002',
  FILE_CORRUPTED = 'E003',
  FILE_UPLOAD_FAILED = 'E004',
  FILE_STORAGE_FAILED = 'E005',
  
  // URL errors (E1xx)
  INVALID_URL = 'E101',
  URL_UNREACHABLE = 'E102',
  URL_TIMEOUT = 'E103',
  URL_BLOCKED = 'E104',
  
  // MCP errors (E2xx)
  MCP_UNAVAILABLE = 'E201',
  MCP_TIMEOUT = 'E202',
  MCP_TOOL_ERROR = 'E203',
  MCP_INVALID_RESPONSE = 'E204',
  
  // Processing errors (E3xx)
  PROCESSING_TIMEOUT = 'E301',
  PROCESSING_FAILED = 'E302',
  EXPORT_FAILED = 'E303',
  PARTIAL_EXPORT_FAILED = 'E304',
  
  // Database errors (E4xx)
  DB_CONNECTION_FAILED = 'E401',
  DB_QUERY_FAILED = 'E402',
  DB_PERSIST_FAILED = 'E403',
  
  // Session errors (E5xx)
  SESSION_EXPIRED = 'E501',
  SESSION_INVALID = 'E502',
  
  // Rate limiting (E6xx)
  RATE_LIMIT_EXCEEDED = 'E601',
  
  // Network errors (E9xx)
  NETWORK_ERROR = 'E901',
  CONNECTION_LOST = 'E902',
  SSE_RECONNECT_FAILED = 'E903',
  UNKNOWN_ERROR = 'E999',
}

export interface ErrorRecovery {
  userMessage: string;
  suggestedAction: string;
  retryable: boolean;
  retryDelay?: number;  // Milliseconds
  logLevel: 'warn' | 'error';
}

export const ERROR_RECOVERY: Record<ErrorCode, ErrorRecovery> = {
  [ErrorCode.FILE_TOO_LARGE]: {
    userMessage: 'File must be under 100 MB.',
    suggestedAction: 'Choose a smaller file or split the document.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.UNSUPPORTED_FORMAT]: {
    userMessage: 'File format not supported.',
    suggestedAction: 'Supported formats: PDF, Word, Excel, PowerPoint, PNG, JPG, TIFF.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.FILE_CORRUPTED]: {
    userMessage: 'File appears to be corrupted.',
    suggestedAction: 'Try re-saving or re-downloading the file.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.FILE_UPLOAD_FAILED]: {
    userMessage: 'File upload failed.',
    suggestedAction: 'Check your connection and try again.',
    retryable: true,
    retryDelay: 1000,
    logLevel: 'error',
  },
  [ErrorCode.FILE_STORAGE_FAILED]: {
    userMessage: 'Could not save file to storage.',
    suggestedAction: 'Please try again. If the problem persists, contact support.',
    retryable: true,
    retryDelay: 2000,
    logLevel: 'error',
  },
  [ErrorCode.INVALID_URL]: {
    userMessage: 'Invalid URL format.',
    suggestedAction: 'Enter a valid HTTP or HTTPS URL.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.URL_UNREACHABLE]: {
    userMessage: 'URL is unreachable.',
    suggestedAction: 'Check the URL is correct and accessible.',
    retryable: true,
    retryDelay: 5000,
    logLevel: 'warn',
  },
  [ErrorCode.URL_TIMEOUT]: {
    userMessage: 'URL request timed out.',
    suggestedAction: 'The website may be slow. Try again later.',
    retryable: true,
    retryDelay: 10000,
    logLevel: 'warn',
  },
  [ErrorCode.URL_BLOCKED]: {
    userMessage: 'This URL is not allowed.',
    suggestedAction: 'Internal and private URLs are blocked for security.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.MCP_UNAVAILABLE]: {
    userMessage: 'Document processing service is temporarily unavailable.',
    suggestedAction: 'Please try again in a few minutes.',
    retryable: true,
    retryDelay: 30000,
    logLevel: 'error',
  },
  [ErrorCode.MCP_TIMEOUT]: {
    userMessage: 'Processing timed out.',
    suggestedAction: 'Large documents may take longer. Try with a smaller file.',
    retryable: true,
    retryDelay: 5000,
    logLevel: 'error',
  },
  [ErrorCode.MCP_TOOL_ERROR]: {
    userMessage: 'An error occurred while processing.',
    suggestedAction: 'Try a different file or check the file is not corrupted.',
    retryable: true,
    retryDelay: 1000,
    logLevel: 'error',
  },
  [ErrorCode.MCP_INVALID_RESPONSE]: {
    userMessage: 'Received invalid response from processor.',
    suggestedAction: 'Please try again.',
    retryable: true,
    retryDelay: 1000,
    logLevel: 'error',
  },
  [ErrorCode.PROCESSING_TIMEOUT]: {
    userMessage: 'Document processing took too long.',
    suggestedAction: 'Try with a smaller document.',
    retryable: true,
    retryDelay: 5000,
    logLevel: 'error',
  },
  [ErrorCode.PROCESSING_FAILED]: {
    userMessage: 'Document processing failed.',
    suggestedAction: 'Please try again or use a different file.',
    retryable: true,
    retryDelay: 2000,
    logLevel: 'error',
  },
  [ErrorCode.EXPORT_FAILED]: {
    userMessage: 'Failed to export document.',
    suggestedAction: 'Try downloading in a different format.',
    retryable: true,
    retryDelay: 1000,
    logLevel: 'error',
  },
  [ErrorCode.PARTIAL_EXPORT_FAILED]: {
    userMessage: 'Some export formats failed.',
    suggestedAction: 'Available formats are shown. Click "Retry" to try failed formats.',
    retryable: true,
    retryDelay: 1000,
    logLevel: 'warn',
  },
  [ErrorCode.DB_CONNECTION_FAILED]: {
    userMessage: 'Database connection failed.',
    suggestedAction: 'Please try again in a moment.',
    retryable: true,
    retryDelay: 5000,
    logLevel: 'error',
  },
  [ErrorCode.DB_QUERY_FAILED]: {
    userMessage: 'Database query failed.',
    suggestedAction: 'Please try again.',
    retryable: true,
    retryDelay: 2000,
    logLevel: 'error',
  },
  [ErrorCode.DB_PERSIST_FAILED]: {
    userMessage: 'Could not save results.',
    suggestedAction: 'Results are still available for download. Try saving again.',
    retryable: true,
    retryDelay: 2000,
    logLevel: 'error',
  },
  [ErrorCode.SESSION_EXPIRED]: {
    userMessage: 'Your session has expired.',
    suggestedAction: 'Refresh the page to start a new session.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.SESSION_INVALID]: {
    userMessage: 'Invalid session.',
    suggestedAction: 'Refresh the page to start a new session.',
    retryable: false,
    logLevel: 'warn',
  },
  [ErrorCode.RATE_LIMIT_EXCEEDED]: {
    userMessage: 'Rate limit reached.',
    suggestedAction: 'Please wait {retryAfter} seconds before trying again.',
    retryable: true,
    retryDelay: 60000,
    logLevel: 'warn',
  },
  [ErrorCode.NETWORK_ERROR]: {
    userMessage: 'Network error.',
    suggestedAction: 'Check your connection and try again.',
    retryable: true,
    retryDelay: 2000,
    logLevel: 'error',
  },
  [ErrorCode.CONNECTION_LOST]: {
    userMessage: 'Connection lost.',
    suggestedAction: 'Reconnecting...',
    retryable: true,
    retryDelay: 1000,
    logLevel: 'warn',
  },
  [ErrorCode.SSE_RECONNECT_FAILED]: {
    userMessage: 'Could not reconnect to server.',
    suggestedAction: 'Click "Retry" to try again.',
    retryable: true,
    retryDelay: 5000,
    logLevel: 'error',
  },
  [ErrorCode.UNKNOWN_ERROR]: {
    userMessage: 'An unexpected error occurred.',
    suggestedAction: 'Please try again. If the problem persists, contact support.',
    retryable: true,
    retryDelay: 2000,
    logLevel: 'error',
  },
};
```

### Appendix B: API Routes

| Route | Method | Description |
|-------|--------|-------------|
| `/api/upload` | POST | File upload, creates Job |
| `/api/process` | POST | MCP dispatch with SSE (supports reconnection) |
| `/api/history` | GET | List jobs for session (paginated) |
| `/api/jobs/[id]` | GET | Get job details |
| `/api/jobs/[id]/results` | GET | Get job results |
| `/api/health` | GET | Health check (cached 30s) |

### Appendix C: .gitignore (Addresses Minor 3.6)

```gitignore
# Dependencies
node_modules/
/.pnp
.pnp.js

# Next.js build
/.next/
/out/
/dist/

# Production
/build/

# Prisma
/node_modules/.prisma/client

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Environment
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Cache
.cache/
.turbo/

# Test
coverage/
.nyc_output/
/playwright-report/
/test-results/

# Misc
*.pem
```

---

## Approval

| Role | Name | Date | Signature |
|------|------|------|-----------|
| CAIO | Jarvis Richardson (Agent Zero) | 2025-12-11 | ✅ APPROVED |
| Technical Lead | Claude Code | 2025-12-11 | ✅ APPROVED |
| Reviewer | GitHub Copilot | 2025-12-11 | ✅ APPROVED |
| Reviewer | Code Analysis Agent | 2025-12-11 | ✅ APPROVED |

### Change Log

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 0.1.0 | 2025-12-11 | Agent Zero | Initial draft |
| 0.2.0 | 2025-12-11 | Agent Zero | Next.js 16, Mermaid diagrams |
| 0.3.0 | 2025-12-11 | Agent Zero | Copilot review feedback |
| 0.4.0 | 2025-12-11 | Agent Zero | Phase 1/2 separation |
| 0.4.1 | 2025-12-11 | Agent Zero | Removed deployment section |
| 0.5.0 | 2025-12-11 | Agent Zero | Added persistent storage, expanded MCP tools |
| 0.6.0 | 2025-12-11 | Agent Zero | **Comprehensive Review Response** |
| | | | **Critical Findings Addressed:** |
| | | | - 1.1: Added Section 6.8 SSE Resilience Strategy |
| | | | - 1.2: Added Section 7.4.1 Session Edge Cases |
| | | | - 1.3: Added Section 8.6 MCP Error Recovery Strategy |
| | | | - 1.4: Added Section 12.5 Database Management Strategy |
| | | | - 1.5: Added Section 8.7 Health Check Implementation |
| | | | - 1.6: Added Section 7.6.1 Large Document Handling |
| | | | - 1.7: Added Section 7.5.1 File Storage Lifecycle |
| | | | - 1.8: Added Section 13.4 Performance Testing |
| | | | - 1.9: Added Section 13.5 Observability & Monitoring |
| | | | **Major Findings Addressed:** |
| | | | - 2.1: Expanded Section 10.4 Keyboard Shortcuts |
| | | | - 2.2: Added Section 8.1.1 Rate Limiting |
| | | | - 2.3: Expanded Section 4.1.3 Export Format Specs |
| | | | - 2.4: Expanded Section 13.2 Component Testing Strategy |
| | | | - 2.5: Added Section 11.3 URL Input Security |
| | | | - 2.6: Deferred plugin architecture to Phase 2 |
| | | | **Minor Findings Addressed:** |
| | | | - 3.1: Added Section 12.3.1 Prisma Client Singleton |
| | | | - 3.2: Added Section 6.3.1 Input State Management |
| | | | - 3.3: Added performance note in Section 10.3 |
| | | | - 3.4: Added Section 6.3.2 Results Viewer Behavior |
| | | | - 3.5: Expanded Appendix A with Error Recovery |
| | | | - 3.6: Updated Appendix C with comprehensive .gitignore |
| | | | - 3.7: Added Section 12.3.2 Type Safety Strategy |
| | | | - 3.8: Added Store Testing in Section 13.2 |

---

**Document Status**: ✅ APPROVED - Ready for Phase 1 Implementation

*This charter covers Phase 1 (Development) only. Phase 2 (Deployment) will be documented in a separate charter.*

*All 23 findings from Code Analysis Agent review have been addressed.*
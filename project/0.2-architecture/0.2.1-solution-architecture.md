# Solution Architecture: HX Docling UI Application

**Document Type**: Solution Architecture
**Version**: 2.1.0
**Status**: APPROVED
**Created**: 2025-12-11
**Last Updated**: 2025-12-11
**Author**: Alex Rivera (Platform Architect)
**Charter Reference**: `project/0.0-charter/0.1-hx-docling-ui-charter.md` v0.7.0
**Review Reference**: `project/0.2-architecture/reviews/03-gap-resolution-for-alex.md`
**Target Audience**: Development Team, Operations, Code Review Agents

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Architecture Overview](#2-architecture-overview)
3. [System Context](#3-system-context)
4. [Container Architecture](#4-container-architecture)
5. [Component Architecture](#5-component-architecture)
6. [Infrastructure Topology](#6-infrastructure-topology)
7. [Technology Stack Decisions](#7-technology-stack-decisions)
8. [Data Architecture](#8-data-architecture)
9. [Integration Patterns](#9-integration-patterns)
10. [Security Architecture](#10-security-architecture)
11. [Error Handling and Resilience](#11-error-handling-and-resilience)
12. [Scalability Considerations](#12-scalability-considerations)
13. [Deployment Architecture](#13-deployment-architecture)
14. [Architecture Decision Records](#14-architecture-decision-records)
15. [Appendices](#15-appendices)

---

## 1. Executive Summary

### 1.1 Purpose

This document defines the comprehensive solution architecture for the HX Docling UI Application, a web-based interface enabling users to process documents through the HX-Infrastructure Docling MCP Server backed by IBM Granite Docling 258M VLM.

### 1.2 Scope

- **Phase 1**: Development environment on hx-cc-server (bare metal Node.js)
- **Components**: Next.js 16 frontend, MCP client integration, PostgreSQL persistence, Redis session management
- **Integration**: 8 MCP tools for document conversion and export (see Charter Section 8.2)

### 1.3 Key Architectural Decisions

| Decision | Rationale | Reference |
|----------|-----------|-----------|
| Next.js 16 with App Router | Forward-looking release, Turbopack improvements, React 19+ support | ADR-001 |
| Bare metal deployment | Phase 1 requirement, CAIO direction | Charter Section 1.4 |
| Zustand for state management | Minimal footprint, SSR-ready, no boilerplate | ADR-002 |
| SSE for real-time progress | Native browser support, reconnection capability | ADR-003 |
| PostgreSQL for persistence | HX-Infrastructure standard, ACID compliance | Charter Section 7 |
| Redis for sessions and rate limiting | Fast, TTL support, distributed state | Charter Section 7.4 |
| PgBouncer for connection pooling | Connection management for multiple instances | ADR-006 |

---

## 2. Architecture Overview

### 2.1 Architecture Style

The HX Docling UI follows a **layered architecture** pattern with clear separation of concerns:

```
+------------------------------------------------------------------+
|                    PRESENTATION LAYER                             |
|  (React Components, shadcn/ui, Client-Side State)                |
+------------------------------------------------------------------+
                              |
                              v
+------------------------------------------------------------------+
|                      API LAYER                                    |
|  (Next.js Route Handlers, SSE Endpoints, Validation)             |
+------------------------------------------------------------------+
                              |
                              v
+------------------------------------------------------------------+
|                   APPLICATION LAYER                               |
|  (MCP Client, SSE Manager, Job Manager, Error Recovery)          |
+------------------------------------------------------------------+
                              |
                              v
+------------------------------------------------------------------+
|                      DATA LAYER                                   |
|  (Prisma ORM, Redis Client, File Storage Manager)                |
+------------------------------------------------------------------+
                              |
                              v
+------------------------------------------------------------------+
|                 EXTERNAL SERVICES                                 |
|  (hx-docling-mcp-server, hx-postgres-server, hx-redis-server)    |
+------------------------------------------------------------------+
```

### 2.2 Architecture Principles

| Principle | Application |
|-----------|-------------|
| **Separation of Concerns** | Clear layer boundaries, each layer has single responsibility |
| **Resilience First** | SSE reconnection, retry logic, graceful degradation |
| **Progressive Disclosure** | UI complexity revealed as needed |
| **Security by Design** | Input validation, SSRF prevention, rate limiting |
| **Observability** | Structured logging, health checks, metrics |
| **Stateless API** | Session state in Redis, no server-side memory state |

---

## 3. System Context

### 3.1 System Context Diagram (C4 Level 1)

```mermaid
graph TB
    subgraph Users["External Users"]
        KW[Knowledge Worker]
        DE[Data Engineer]
        AD[AI Developer]
        SH[Stakeholder]
    end

    subgraph System["HX Docling UI System"]
        UI[hx-docling-ui<br/>Next.js 16 Application]
    end

    subgraph External["HX-Infrastructure External Systems"]
        MCP[hx-docling-mcp-server<br/>Document Processing]
        PG[hx-postgres-server<br/>Data Persistence]
        RD[hx-redis-server<br/>Session Management]
        LLM[hx-litellm-server<br/>LLM Routing]
        OL3[hx-ollama3-server<br/>IBM Granite Docling 258M]
    end

    KW -->|Upload documents,<br/>view results| UI
    DE -->|Batch URL processing| UI
    AD -->|Test document processing| UI
    SH -->|Demo capabilities| UI

    UI -->|MCP Protocol<br/>JSON-RPC 2.0 + SSE| MCP
    UI -->|SQL queries<br/>via Prisma| PG
    UI -->|Session management<br/>Redis protocol| RD

    MCP -->|LLM requests| LLM
    LLM -->|Model inference| OL3

    style UI fill:#3b82f6,color:#fff
    style MCP fill:#22c55e,color:#fff
    style PG fill:#f59e0b,color:#fff
    style RD fill:#ef4444,color:#fff
```

### 3.2 External System Dependencies

| System | Purpose | Protocol | Criticality |
|--------|---------|----------|-------------|
| hx-docling-mcp-server | Document conversion via MCP tools | HTTP/SSE (JSON-RPC 2.0) | **Critical** |
| hx-postgres-server | Job and result persistence | PostgreSQL (SSL) | **Critical** |
| hx-redis-server | Session tracking | Redis protocol | **Critical** |
| hx-litellm-server | LLM routing (transitive) | HTTP | Transitive |
| hx-ollama3-server | Model serving (transitive) | HTTP | Transitive |

**Reference**: Charter Section 8.4 - Infrastructure Dependencies

---

## 4. Container Architecture

### 4.1 Container Diagram (C4 Level 2)

```mermaid
graph TB
    subgraph Browser["User Browser"]
        SPA[Single Page Application<br/>React 19 + shadcn/ui]
    end

    subgraph DevServer["hx-cc-server (192.168.10.224)"]
        subgraph NextJS["hx-docling-ui (Next.js 16)"]
            RC[React Components<br/>Server + Client]
            API[API Route Handlers<br/>/api/v1/*]
            SSE_EP[SSE Endpoint<br/>/api/v1/process/{jobId}/events]
        end

        subgraph AppServices["Application Services"]
            MCPClient[MCP Client<br/>lib/mcp/client.ts]
            SSEMgr[SSE Manager<br/>lib/sse/manager.ts]
            JobMgr[Job Manager<br/>Zustand Store]
        end

        subgraph DataAccess["Data Access Layer"]
            Prisma[Prisma Client<br/>lib/db/prisma.ts]
            RedisClient[Redis Client<br/>lib/redis/client.ts]
            FileMgr[File Manager<br/>lib/utils/storage.ts]
        end

        FS[File Storage<br/>/data/docling-uploads/]
    end

    subgraph HXInfra["HX-Infrastructure"]
        MCP[hx-docling-mcp-server<br/>:8000]
        PG[(hx-postgres-server<br/>:5432)]
        RD[(hx-redis-server<br/>:6379)]
    end

    SPA -->|HTTPS| RC
    SPA <-->|SSE Stream| SSE_EP
    RC --> API
    API --> MCPClient
    API --> SSEMgr
    API --> JobMgr
    MCPClient -->|JSON-RPC 2.0| MCP
    SSEMgr --> JobMgr
    JobMgr --> Prisma
    Prisma --> PG
    JobMgr --> RedisClient
    RedisClient --> RD
    FileMgr --> FS
    API --> FileMgr

    style NextJS fill:#1a1a2e,stroke:#16213e,color:#eee
    style AppServices fill:#16213e,stroke:#0f3460,color:#eee
    style DataAccess fill:#0f3460,stroke:#16213e,color:#eee
```

### 4.2 Container Responsibilities

| Container | Responsibility | Technology |
|-----------|----------------|------------|
| **React Components** | UI rendering, user interaction, client-side state | React 19, shadcn/ui, Tailwind CSS |
| **API Route Handlers** | Request validation, MCP dispatch, response formatting | Next.js Route Handlers |
| **SSE Endpoint** | Real-time progress streaming, reconnection support | Native fetch API |
| **MCP Client** | MCP protocol implementation, tool invocation | Custom TypeScript client |
| **SSE Manager** | Connection lifecycle, backoff, fallback to polling | Custom implementation |
| **Job Manager** | Job state tracking, progress updates | Zustand store |
| **Prisma Client** | Database operations, type-safe queries | Prisma ORM 5.x |
| **Redis Client** | Session CRUD, TTL management | ioredis 5.x |
| **File Manager** | Upload storage, cleanup, lifecycle | Node.js fs module |

---

## 5. Component Architecture

### 5.1 Component Diagram (C4 Level 3)

```mermaid
graph TB
    subgraph Presentation["Presentation Layer"]
        subgraph Input["Input Components"]
            UZ[UploadZone.tsx<br/>Client Component]
            UI_URL[UrlInput.tsx<br/>Client Component]
            FP[FilePreview.tsx<br/>Client Component]
        end

        subgraph Progress["Progress Components"]
            PC[ProgressCard.tsx<br/>Client Component]
            SB[StatusBadge.tsx<br/>Server Component]
            LS[LoadingStates.tsx<br/>Client Component]
        end

        subgraph Results["Results Components"]
            RV[ResultsViewer.tsx<br/>Client Component]
            MV[MarkdownView.tsx<br/>Server Component]
            HV[HtmlView.tsx<br/>Server Component]
            JV[JsonView.tsx<br/>Server Component]
            DB[DownloadButton.tsx<br/>Client Component]
        end

        subgraph History["History Components"]
            HVW[HistoryView.tsx<br/>Server Component]
            JD[JobDetail.tsx<br/>Client Component]
            PG[Pagination.tsx<br/>Server Component]
        end

        subgraph Error["Error Components"]
            ED[ErrorDisplay.tsx<br/>Client Component]
            ER[ErrorRecovery.tsx<br/>Client Component]
            EB[ErrorBoundary.tsx<br/>Client Component]
        end
    end

    subgraph API["API Layer (v1)"]
        UP_API[/api/v1/upload<br/>POST]
        PR_API[/api/v1/process<br/>POST]
        PR_SSE_API[/api/v1/process/{jobId}/events<br/>GET SSE]
        HI_API[/api/v1/history<br/>GET]
        JB_API[/api/v1/jobs/[id]<br/>GET]
        HL_API[/api/v1/health<br/>GET]
    end

    subgraph Stores["State Management"]
        DS[documentStore<br/>File/URL + Results]
        US[uiStore<br/>Modals + Toasts]
    end

    subgraph Hooks["Custom Hooks"]
        useUpload[useUpload]
        useProcess[useProcess]
        useSSE[useSSE]
        useDownload[useDownload]
        useHistory[useHistory]
    end

    UZ --> useUpload
    UI_URL --> useUpload
    useUpload --> UP_API
    useUpload --> DS

    PC --> useProcess
    useProcess --> PR_API
    useProcess --> useSSE
    useSSE --> DS

    RV --> DS
    DB --> useDownload

    HVW --> useHistory
    useHistory --> HI_API

    ED --> US
    ER --> DS

    style Presentation fill:#1a1a2e,stroke:#16213e,color:#eee
    style API fill:#16213e,stroke:#0f3460,color:#eee
    style Stores fill:#0f3460,stroke:#16213e,color:#eee
```

### 5.2 Component Boundaries

**Reference**: Charter Section 6.3 - Server vs Client Component Boundaries

| Component Type | Characteristics | Examples |
|----------------|-----------------|----------|
| **Server Components** | No interactivity, SSR-rendered, 0 KB client bundle | Header, Footer, MarkdownView, HtmlView, JsonView, Pagination |
| **Client Components** | User interaction, browser events, `'use client'` directive | UploadZone, UrlInput, ProgressCard, ResultsViewer, DownloadButton, ErrorBoundary |

### 5.2.1 Server/Client Component Composition Pattern

**CRITICAL**: React 19 Server Components have strict composition rules. Client Components cannot directly import Server Components as regular children.

**Correct Pattern - "Donut" Pattern**:
```
Layout (Server Component)
  |-- Header (Server Component)
  |-- MainContent (Server Component wrapper)
  |     +-- {children} prop receives Client Components
  |     |-- DocumentUploadFlow (Client Component)
  |           +-- UploadZone (Client Component)
  +-- Footer (Server Component)
```

**Implementation Example**:
```typescript
// app/page.tsx (Server Component)
import { DocumentUploadFlow } from '@/components/upload/DocumentUploadFlow';
import { HistoryView } from '@/components/history/HistoryView';

export default function Page() {
  return (
    <main className="container mx-auto">
      {/* Server Component wraps Client Component */}
      <DocumentUploadFlow />

      {/* Server Component can render directly */}
      <HistoryView />
    </main>
  );
}

// components/upload/DocumentUploadFlow.tsx (Client Component)
'use client';

import { UploadZone } from './UploadZone';
import { ProgressCard } from '../progress/ProgressCard';
import { useDocumentStore } from '@/stores/documentStore';

export function DocumentUploadFlow() {
  const { state } = useDocumentStore();
  // Client-side interactivity
  return (
    <div>
      <UploadZone />
      {state === 'processing' && <ProgressCard />}
    </div>
  );
}
```

**Anti-Pattern to Avoid**:
```typescript
// WRONG: Client Component trying to render Server Component
'use client';
import { MarkdownView } from './MarkdownView'; // Server Component

export function ResultsViewer() {
  // This will fail at build time!
  return <MarkdownView content={content} />;
}
```

**Correct Approach for Results**:
```typescript
// ResultsViewer.tsx (Server Component wrapper)
import { Suspense } from 'react';
import { MarkdownView } from './MarkdownView';
import { ResultsInteractive } from './ResultsInteractive';

export async function ResultsViewer({ jobId }: { jobId: string }) {
  const result = await getResult(jobId);

  return (
    <div>
      {/* Server Component renders static content */}
      <MarkdownView content={result.markdown} />

      {/* Client Component handles interactivity */}
      <ResultsInteractive jobId={jobId} />
    </div>
  );
}
```

### 5.2.2 Accessibility Implementation (WCAG 2.1 AA)

The application must meet WCAG 2.1 Level AA compliance. shadcn/ui components provide baseline accessibility but require additional implementation.

**ARIA Live Regions for Progress Updates**:
```typescript
// ProgressCard.tsx
'use client';

export function ProgressCard({ progress }: { progress: Progress }) {
  return (
    <div
      role="progressbar"
      aria-valuenow={progress.percent}
      aria-valuemin={0}
      aria-valuemax={100}
      aria-label={`Document processing: ${progress.message}`}
      aria-live="polite"
    >
      <Progress value={progress.percent} />
      <span className="sr-only">{progress.message}</span>
    </div>
  );
}
```

**Keyboard Navigation Patterns**:
| Action | Key | Context |
|--------|-----|---------|
| Navigate form elements | Tab | Global |
| Activate button/link | Enter, Space | Focused element |
| Close modal/dialog | Escape | Modal context |
| Navigate history items | Arrow Up/Down | History list |
| Select format | Arrow Left/Right | Format tabs |

**Focus Management**:
```typescript
// On state transitions, manage focus appropriately
useEffect(() => {
  if (state === 'error') {
    // Focus error message for screen reader announcement
    errorRef.current?.focus();
  } else if (state === 'complete') {
    // Focus results area
    resultsRef.current?.focus();
  }
}, [state]);
```

**Color Contrast Requirements**:
- Text: minimum 4.5:1 ratio (AA)
- Large text (18px+): minimum 3:1 ratio
- UI components: minimum 3:1 ratio
- Use `@axe-core/react` for automated testing

**Testing Strategy**:
| Method | Tool | Frequency |
|--------|------|-----------|
| Automated | @axe-core/react | Every PR |
| Screen reader | NVDA (Windows), VoiceOver (Mac) | Sprint review |
| Keyboard | Manual testing | Every component |
| Color contrast | WebAIM Contrast Checker | Design phase |

### 5.3 State Management Architecture

```mermaid
stateDiagram-v2
    [*] --> Idle: Initial State

    Idle --> FileSelected: User drops file
    Idle --> UrlEntered: User pastes URL

    FileSelected --> Uploading: Submit clicked
    UrlEntered --> Processing: Submit clicked

    Uploading --> Processing: Upload complete
    Uploading --> Error: Upload failed

    Processing --> Retry1: MCP error (transient)
    Retry1 --> Processing: Retry succeeds
    Retry1 --> Retry2: Still failing
    Retry2 --> Processing: Retry succeeds
    Retry2 --> Retry3: Still failing
    Retry3 --> Processing: Retry succeeds
    Retry3 --> Error: All retries exhausted

    Processing --> Complete: MCP returns result
    Processing --> PartialComplete: Some exports failed
    Processing --> Error: Fatal MCP error

    Complete --> Persisted: Results saved to DB
    PartialComplete --> Persisted: Partial results saved

    Persisted --> Idle: User clicks reset

    Error --> Idle: User clicks retry
    Error --> FileSelected: User selects new file
    Error --> UrlEntered: User enters new URL
```

**Reference**: Charter Section 6.5 - State Management

### 5.3.1 Loading State UI Design

The Processing state includes sub-states to provide clear visual feedback:

```mermaid
stateDiagram-v2
    [*] --> Processing

    state Processing {
        [*] --> Initial
        Initial --> Streaming: First SSE event
        Streaming --> Streaming: Progress events
        Streaming --> Retry: Connection lost
        Retry --> Streaming: Reconnected
        Retry --> Polling: SSE unavailable
        Polling --> Polling: Poll response
    }

    Processing --> Complete: Final event
    Processing --> Error: Fatal error
```

**UI State Variants**:

| State | Visual | Message | Component |
|-------|--------|---------|-----------|
| `Processing.Initial` | Spinner | "Starting..." | ProgressCard with indeterminate spinner |
| `Processing.Streaming` | Progress bar | "Processing with AI... (45%)" | ProgressCard with determinate progress |
| `Processing.Retry` | Spinner + counter | "Reconnecting... (attempt 2/10)" | ProgressCard with retry indicator |
| `Processing.Polling` | Pulsing indicator | "Using compatibility mode" | ProgressCard with polling badge |

**Implementation**:
```typescript
// ProgressCard with state variants
'use client';

type ProcessingSubState = 'initial' | 'streaming' | 'retry' | 'polling';

interface ProgressCardProps {
  subState: ProcessingSubState;
  progress: number;
  message: string;
  retryCount?: number;
  maxRetries?: number;
}

export function ProgressCard({
  subState,
  progress,
  message,
  retryCount = 0,
  maxRetries = 10,
}: ProgressCardProps) {
  return (
    <Card>
      <CardContent className="pt-6">
        {subState === 'initial' && (
          <div className="flex items-center gap-3">
            <Loader2 className="h-5 w-5 animate-spin" />
            <span>Starting...</span>
          </div>
        )}

        {subState === 'streaming' && (
          <div className="space-y-2">
            <Progress value={progress} aria-label={message} />
            <p className="text-sm text-muted-foreground">{message}</p>
          </div>
        )}

        {subState === 'retry' && (
          <div className="flex items-center gap-3">
            <RefreshCw className="h-5 w-5 animate-spin" />
            <span>Reconnecting... (attempt {retryCount}/{maxRetries})</span>
          </div>
        )}

        {subState === 'polling' && (
          <div className="space-y-2">
            <Badge variant="secondary">Compatibility Mode</Badge>
            <Progress value={progress} />
            <p className="text-sm text-muted-foreground">
              Using polling - refresh speeds may be slower
            </p>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
```

### 5.3.2 Connection Status Indicator

Display connection status in the application header:

```typescript
// ConnectionIndicator.tsx
'use client';

type ConnectionStatus = 'connected' | 'polling' | 'disconnected';

export function ConnectionIndicator({ status }: { status: ConnectionStatus }) {
  const config = {
    connected: { color: 'bg-green-500', label: 'Connected (SSE)' },
    polling: { color: 'bg-yellow-500', label: 'Polling Mode' },
    disconnected: { color: 'bg-red-500', label: 'Disconnected' },
  };

  return (
    <div className="flex items-center gap-2" aria-label={`Connection: ${config[status].label}`}>
      <span className={`h-2 w-2 rounded-full ${config[status].color}`} />
      <span className="text-xs text-muted-foreground">{config[status].label}</span>
    </div>
  );
}
```

---

## 6. Infrastructure Topology

### 6.1 Network Topology

```
+-------------------------------------------------------------------------+
|                        HX-Infrastructure Network                         |
|                          192.168.10.0/24                                 |
|                                                                          |
|  +-------------------+     +----------------------+                      |
|  | hx-cc-server      |     | hx-docling-mcp-server|                      |
|  | 192.168.10.224    |     | 192.168.10.217      |                      |
|  | Port: 3000        |---->| Port: 8000          |                      |
|  | (Next.js Dev)     |     | (MCP Server)        |                      |
|  +-------------------+     +----------+-----------+                      |
|           |                          |                                   |
|           |                          v                                   |
|           |               +----------------------+                       |
|           |               | hx-litellm-server    |                       |
|           |               | 192.168.10.212:4000  |                       |
|           |               +----------+-----------+                       |
|           |                          |                                   |
|           |                          v                                   |
|           |               +----------------------+                       |
|           |               | hx-ollama3-server    |                       |
|           |               | 192.168.10.206:11434 |                       |
|           |               | (Granite Docling 258M)|                      |
|           |               +----------------------+                       |
|           |                                                              |
|           v                                                              |
|  +-------------------+     +----------------------+                      |
|  | hx-postgres-server|     | hx-redis-server     |                      |
|  | 192.168.10.208    |     | 192.168.10.209      |                      |
|  | Port: 6432 (PgB)  |     | Port: 6379 (auth)   |                      |
|  | Port: 5432 (SSL)  |     | (Session + Rate)    |                      |
|  | (Job persistence) |     |                     |                      |
|  +-------------------+     +----------------------+                      |
|                                                                          |
+-------------------------------------------------------------------------+
```

### 6.1.1 Firewall Rules Specification

**Required firewall rules for hx-cc-server**:

| Source | Destination | Port | Protocol | Purpose |
|--------|-------------|------|----------|---------|
| hx-cc-server | hx-docling-mcp-server | 8000 | TCP/HTTP | MCP API calls |
| hx-cc-server | hx-postgres-server | 6432 | TCP/SSL | PgBouncer connection |
| hx-cc-server | hx-postgres-server | 5432 | TCP/SSL | Direct DB (migrations only) |
| hx-cc-server | hx-redis-server | 6379 | TCP | Redis session/rate limiting |
| Any (internal) | hx-cc-server | 3000 | TCP/HTTP | Application access |

**UFW Rules for hx-cc-server**:
```bash
# Allow outbound to MCP server
sudo ufw allow out to 192.168.10.217 port 8000 proto tcp

# Allow outbound to PostgreSQL via PgBouncer
sudo ufw allow out to 192.168.10.208 port 6432 proto tcp

# Allow outbound to PostgreSQL direct (migrations)
sudo ufw allow out to 192.168.10.208 port 5432 proto tcp

# Allow outbound to Redis
sudo ufw allow out to 192.168.10.209 port 6379 proto tcp

# Allow inbound application access from internal network
sudo ufw allow from 192.168.10.0/24 to any port 3000 proto tcp

# Deny all other outbound by default (whitelist approach)
sudo ufw default deny outgoing
sudo ufw default deny incoming
```

**Network Security Zones**:
- **Application Zone**: hx-cc-server (192.168.10.224)
- **Service Zone**: hx-docling-mcp-server, hx-litellm-server, hx-ollama3-server
- **Data Zone**: hx-postgres-server, hx-redis-server
- **Trust Boundary**: All traffic within 192.168.10.0/24 (internal network only)

### 6.2 Server Specifications

| Server | IP Address | Port | Service | Status |
|--------|------------|------|---------|--------|
| hx-cc-server | 192.168.10.224 | 3000 | Next.js Development Server | Operational |
| hx-docling-mcp-server | 192.168.10.217 | 8000 | MCP Document Processing | Operational |
| hx-postgres-server | 192.168.10.208 | 6432 | PgBouncer Connection Pooler | Operational |
| hx-postgres-server | 192.168.10.208 | 5432 | PostgreSQL Direct (migrations) | Operational |
| hx-redis-server | 192.168.10.209 | 6379 | Redis Session + Rate Limiting | Operational |
| hx-litellm-server | 192.168.10.212 | 4000 | LLM Routing (transitive) | Operational |
| hx-ollama3-server | 192.168.10.206 | 11434 | Model Serving (transitive) | Operational |

**Reference**: Charter Section 8.4 - Infrastructure Dependencies

### 6.3 Storage Topology

```
hx-cc-server (192.168.10.224)
|
+-- /home/agent0/hx-docling-ui/       # Application root
|   +-- src/                          # Source code
|   +-- prisma/                       # Database schema & migrations
|   +-- public/                       # Static assets
|
+-- /data/docling-uploads/            # Persistent file storage (500 GB)
|   +-- 2025/
|       +-- 12/
|           +-- 11/
|               +-- {uuid}-document.pdf
|
+-- /tmp/docling-processing/          # Temporary upload staging
```

**Reference**: Charter Section 7.5 - File Storage Structure

### 6.3.1 Disk Space Monitoring and Alerting

The `/data/docling-uploads/` partition (500 GB) requires proactive monitoring to prevent upload failures.

**Prometheus Metrics Configuration**:
```yaml
# prometheus/rules/disk-alerts.yml
groups:
  - name: disk_alerts
    rules:
      - alert: DiskSpaceWarning
        expr: (node_filesystem_avail_bytes{mountpoint="/data"} / node_filesystem_size_bytes{mountpoint="/data"}) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space warning on /data partition"
          description: "Less than 20% disk space remaining ({{ $value | printf \"%.1f\" }}%)"

      - alert: DiskSpaceCritical
        expr: (node_filesystem_avail_bytes{mountpoint="/data"} / node_filesystem_size_bytes{mountpoint="/data"}) * 100 < 5
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Critical disk space on /data partition"
          description: "Less than 5% disk space remaining ({{ $value | printf \"%.1f\" }}%)"
```

**Alerting Thresholds**:
| Threshold | Level | Action |
|-----------|-------|--------|
| 80% used (20% free) | Warning | Notify operations team |
| 95% used (5% free) | Critical | Page on-call, return E005 to users |
| 99% used | Emergency | Block new uploads, emergency cleanup |

**Application-Level Handling**:
```typescript
// Check disk space before accepting upload
async function checkDiskSpace(): Promise<{ available: boolean; freePercent: number }> {
  const stats = await fs.statfs('/data/docling-uploads');
  const freePercent = (stats.bavail / stats.blocks) * 100;

  if (freePercent < 5) {
    throw new AppError('E005', 'Storage temporarily unavailable. Please try again later.');
  }

  return { available: true, freePercent };
}
```

**Grafana Dashboard Panel**:
- Metric: `node_filesystem_avail_bytes{mountpoint="/data"}`
- Display: Gauge with thresholds (green > 20%, yellow 5-20%, red < 5%)
- Include: Historical trend (7 days)

---

## 7. Technology Stack Decisions

### 7.1 Technology Stack Overview

| Layer | Technology | Version | Rationale |
|-------|------------|---------|-----------|
| **Framework** | Next.js | 16.x | App Router, Turbopack improvements, React 19+ |
| **Runtime** | Node.js | >= 20.9.0 | Next.js 16 minimum requirement |
| **UI Components** | shadcn/ui | Latest | HX-Infrastructure standard |
| **Styling** | Tailwind CSS | 3.4.x | shadcn dependency |
| **State Management** | Zustand | 5.x | Minimal footprint, SSR-ready |
| **Validation** | Zod | 3.x | Runtime type safety |
| **Database ORM** | Prisma | 5.x | Type-safe PostgreSQL access |
| **Redis Client** | ioredis | 5.x | Session and rate limiting |
| **HTTP Client** | Native fetch | - | Streaming SSE support |
| **TypeScript** | >= 5.0.0 | - | Next.js 16 requirement |
| **Form Handling** | react-hook-form | 7.x | Type-safe form state |
| **Icons** | lucide-react | Latest | Tree-shakable icons |
| **Class Utilities** | clsx + tailwind-merge | Latest | Conditional class composition |

**Reference**: Charter Section 6.1 - Technology Stack

### 7.2 Technology Selection Rationale

#### ADR-001: Next.js 16 Selection

**Context**: Need a React framework for SSR, API routes, and modern development experience. This architecture targets Next.js 16 as a forward-looking design.

**Decision**: Use Next.js 16 with App Router.

**Rationale**:
- Next.js 16 provides latest framework capabilities with improved performance
- Enhanced Turbopack integration for faster development cycles
- React 19+ support with Server Components
- Built-in API routes for backend functionality
- Streaming SSE support via Route Handlers
- Server Actions for mutations
- HX-Infrastructure alignment

**Turbopack Status**:
- Next.js 16.x: Turbopack fully integrated with production-ready performance

**Alternatives Considered**:
- Remix: Less mature ecosystem, smaller community
- Vite + React: No SSR without additional setup
- Next.js 14: Missing React 19 and Server Actions improvements

#### ADR-002: Zustand for State Management

**Context**: Need client-side state management for document processing workflow.

**Decision**: Use Zustand 5.x.

**Rationale**:
- Minimal bundle size (~1KB gzipped)
- No boilerplate (unlike Redux)
- SSR-compatible
- Simple API with TypeScript support
- Suitable for medium complexity state

**Alternatives Considered**:
- Redux Toolkit: Overkill for this use case, more boilerplate
- Jotai: Atomic approach not needed for this workflow
- React Context: Not optimized for frequent updates

#### ADR-003: SSE for Real-Time Progress

**Context**: Need real-time progress updates during document processing.

**Decision**: Use Server-Sent Events (SSE) with reconnection logic.

**Rationale**:
- Native browser support
- Unidirectional (server to client) fits use case
- Simpler than WebSocket for one-way streaming
- Built-in reconnection with Last-Event-ID
- Lower overhead than WebSocket

**Alternatives Considered**:
- WebSocket: Bidirectional not needed, more complex
- Polling: Higher latency, more server load
- Long polling: More complex connection management

---

## 8. Data Architecture

### 8.1 Database Schema

```mermaid
erDiagram
    Job ||--o{ Result : has

    Job {
        uuid id PK
        string sessionId FK
        enum status
        enum inputType
        string fileName
        int fileSize
        string filePath
        string mimeType
        string url
        string currentStage
        int currentPercent
        string currentMessage
        datetime createdAt
        datetime updatedAt
        datetime completedAt
        string error
        string errorCode
        int retryCount
    }

    Result {
        uuid id PK
        uuid jobId FK
        enum format
        text content
        int size
        datetime createdAt
    }
```

**Reference**: Charter Section 7.3 - Database Schema (Prisma)

### 8.1.1 Database Index Strategy

```prisma
// prisma/schema.prisma - Index definitions

model Job {
  id             String    @id @default(uuid())
  sessionId      String
  status         JobStatus
  inputType      InputType
  fileName       String?
  fileSize       Int?
  filePath       String?
  mimeType       String?
  url            String?
  currentStage   String?
  currentPercent Int?
  currentMessage String?
  checkpointData Json?                           // JSONB for checkpoint/resume capability
  createdAt      DateTime  @default(now()) @db.Timestamptz
  updatedAt      DateTime  @updatedAt @db.Timestamptz
  completedAt    DateTime? @db.Timestamptz
  error          String?
  errorCode      String?
  retryCount     Int       @default(0)

  results        Result[]

  // Indexes for common query patterns
  @@index([sessionId])                           // History by session
  @@index([status, createdAt(sort: Desc)])       // Active jobs, recent first
  @@index([completedAt])                         // Cleanup queries
}

model Result {
  id        String       @id @default(uuid())
  jobId     String
  format    ResultFormat
  content   String       @db.Text
  size      Int
  createdAt DateTime     @default(now()) @db.Timestamptz

  job       Job          @relation(fields: [jobId], references: [id], onDelete: Cascade)

  @@index([jobId, format])                       // Result lookup by job and format
}
```

**Index Analysis Schedule**: Run `pg_stat_statements` analysis quarterly to identify slow queries and missing indexes.

### 8.1.2 PostgreSQL Configuration

**Transaction Isolation for Job Updates**:
```typescript
// Prevent race conditions on job status updates
await prisma.$transaction(
  async (tx) => {
    const job = await tx.job.findUnique({
      where: { id: jobId },
      select: { status: true, retryCount: true },
    });

    if (job?.status !== 'PROCESSING') {
      throw new Error('Job not in processing state');
    }

    return tx.job.update({
      where: { id: jobId },
      data: { status: newStatus, completedAt: new Date() },
    });
  },
  { isolationLevel: Prisma.TransactionIsolationLevel.Serializable }
);
```

**Timestamp Configuration**: All timestamps use `TIMESTAMPTZ` to avoid timezone ambiguity:
```prisma
createdAt   DateTime  @default(now()) @db.Timestamptz
updatedAt   DateTime  @updatedAt @db.Timestamptz
completedAt DateTime? @db.Timestamptz
```

**SSL Configuration**: Production requires certificate verification:
```
# Development
sslmode=require

# Production (Phase 2)
sslmode=verify-full
sslrootcert=/etc/ssl/certs/hx-postgres-ca.crt
```

**Database User Privileges**:
```sql
-- Application user (minimal permissions)
CREATE ROLE docling_app WITH LOGIN PASSWORD 'xxx';
GRANT CONNECT ON DATABASE docling_db TO docling_app;
GRANT USAGE ON SCHEMA public TO docling_app;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO docling_app;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO docling_app;

-- Migration user (schema changes only)
CREATE ROLE docling_migration WITH LOGIN PASSWORD 'xxx';
GRANT ALL PRIVILEGES ON DATABASE docling_db TO docling_migration;
```

### 8.1.3 PgBouncer Connection Pooling

**Configuration** (`/etc/pgbouncer/pgbouncer.ini` on hx-postgres-server):
```ini
[databases]
docling_db = host=127.0.0.1 port=5432 dbname=docling_db

[pgbouncer]
listen_addr = 0.0.0.0
listen_port = 6432
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt

; Transaction pooling for stateless queries
pool_mode = transaction

; Pool sizing for ~10 concurrent users
default_pool_size = 25
max_client_conn = 100
reserve_pool_size = 5
reserve_pool_timeout = 3

; Connection limits
max_db_connections = 50
max_user_connections = 50

; Timeouts
server_connect_timeout = 15
server_idle_timeout = 600
query_timeout = 300
```

**Application DATABASE_URL**:
```env
# Use PgBouncer for application connections
DATABASE_URL=postgresql://docling_app:${DB_PASSWORD}@hx-postgres-server.hx.dev.local:6432/docling_db?sslmode=require

# Use direct connection for migrations only
DIRECT_DATABASE_URL=postgresql://docling_migration:${MIGRATION_PASSWORD}@hx-postgres-server.hx.dev.local:5432/docling_db?sslmode=require
```

**Prisma Configuration**:
```typescript
// prisma/schema.prisma
datasource db {
  provider  = "postgresql"
  url       = env("DATABASE_URL")
  directUrl = env("DIRECT_DATABASE_URL")  // For migrations
}
```

### 8.2 Data Flow

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Next.js UI
    participant API as API Routes
    participant FS as File Storage
    participant PG as PostgreSQL
    participant RD as Redis
    participant MCP as MCP Server

    Note over RD: Get/Create Session ID
    UI->>RD: Get session (cookie)
    RD-->>UI: sessionId

    alt File Upload Flow
        U->>UI: Drop PDF file
        UI->>API: POST /api/upload
        API->>FS: Store at /data/docling-uploads/{uuid}
        API->>PG: Create Job record (PENDING)
        API-->>UI: { jobId, fileId }
    else URL Input Flow
        U->>UI: Paste URL
        UI->>API: POST /api/upload (URL mode)
        API->>PG: Create Job record (PENDING)
        API-->>UI: { jobId }
    end

    U->>UI: Click Process
    UI->>API: POST /api/process (SSE)
    API->>PG: Update Job (PROCESSING)

    API->>MCP: MCP tools/call (convert_*)

    loop SSE Progress Stream
        MCP-->>API: Progress event
        API-->>UI: SSE: { stage, percent, message }
    end

    MCP-->>API: Complete with DoclingDocument
    API->>MCP: MCP tools/call (export_markdown)
    API->>MCP: MCP tools/call (export_html)
    API->>MCP: MCP tools/call (export_json)

    API->>PG: Store Results (MD, HTML, JSON)
    API->>PG: Update Job (COMPLETE)
    API-->>UI: SSE: complete with results
```

**Reference**: Charter Section 6.7 - Data Flow

### 8.3 Data Retention Policy

| Data Type | Storage | Retention | Cleanup Method |
|-----------|---------|-----------|----------------|
| Job records | PostgreSQL | 90 days | pg_cron daily (03:00 UTC) |
| Result content | PostgreSQL | 90 days | Cascade delete with Job |
| Uploaded files | /data/docling-uploads/ | 30 days | pg_cron daily (02:00 UTC) |
| Redis sessions | Redis | 24 hours | Redis TTL auto-expire |
| Orphaned files | /data/docling-uploads/orphaned/ | 7 days | Weekly reconciliation |

**Reference**: Charter Section 7.6 - Data Retention Policy

### 8.3.1 Automated Data Retention with pg_cron

**pg_cron Extension Setup** (on hx-postgres-server):
```sql
-- Enable pg_cron extension
CREATE EXTENSION IF NOT EXISTS pg_cron;

-- Grant usage to application database
GRANT USAGE ON SCHEMA cron TO postgres;
```

**Job Cleanup Schedule**:
```sql
-- Delete completed jobs older than 90 days (daily at 03:00 UTC)
-- Batch deletion to avoid long-running locks
SELECT cron.schedule(
  'cleanup-old-jobs',
  '0 3 * * *',
  $$
  WITH deleted AS (
    DELETE FROM "Job"
    WHERE "completedAt" < NOW() - INTERVAL '90 days'
    AND id IN (
      SELECT id FROM "Job"
      WHERE "completedAt" < NOW() - INTERVAL '90 days'
      LIMIT 1000
    )
    RETURNING id
  )
  SELECT count(*) FROM deleted;
  $$
);

-- Results are cascade-deleted via FK constraint
```

**File Cleanup Schedule**:
```sql
-- Notify application to clean files (daily at 02:00 UTC)
SELECT cron.schedule(
  'cleanup-old-files',
  '0 2 * * *',
  $$
  SELECT pg_notify('file_cleanup', json_build_object(
    'action', 'cleanup',
    'older_than_days', 30
  )::text);
  $$
);
```

**Application File Cleanup Listener**:
```typescript
// src/lib/cleanup/file-cleanup.ts
import { prisma } from '@/lib/db/prisma';
import { unlink } from 'fs/promises';
import { join } from 'path';

// Listen for cleanup notifications
prisma.$on('notification', async (event) => {
  if (event.channel === 'file_cleanup') {
    const { older_than_days } = JSON.parse(event.payload);
    await cleanupOldFiles(older_than_days);
  }
});

async function cleanupOldFiles(olderThanDays: number) {
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - olderThanDays);

  // Find jobs with files older than cutoff
  const jobsWithFiles = await prisma.job.findMany({
    where: {
      filePath: { not: null },
      createdAt: { lt: cutoffDate },
    },
    select: { id: true, filePath: true },
  });

  for (const job of jobsWithFiles) {
    if (job.filePath) {
      try {
        await unlink(job.filePath);
        await prisma.job.update({
          where: { id: job.id },
          data: { filePath: null },
        });
      } catch (err) {
        console.error(`Failed to delete file: ${job.filePath}`, err);
      }
    }
  }
}
```

**Monitoring Cleanup Jobs**:
```sql
-- View scheduled jobs
SELECT * FROM cron.job;

-- View job run history
SELECT * FROM cron.job_run_details
ORDER BY start_time DESC
LIMIT 20;
```

---

## 9. Integration Patterns

### 9.1 MCP Client Integration

```mermaid
flowchart LR
    subgraph Client["MCP Client (lib/mcp/client.ts)"]
        Init[Initialize Handler]
        Registry[Tool Registry Cache]
        Req[Request Builder]
        Exec[Tool Executor]
        Parse[Response Parser]
    end

    subgraph MCP["hx-docling-mcp-server:8000"]
        HTTP[HTTP Transport<br/>/mcp]
        SSE[SSE Transport<br/>/mcp]
        Tools[19 MCP Tools]
    end

    Init -->|initialize| HTTP
    Init -->|tools/list| HTTP
    HTTP -->|capabilities| Registry
    Req -->|JSON-RPC 2.0| HTTP
    Exec -->|Streaming| SSE
    HTTP --> Tools
    SSE --> Tools
    Tools --> Parse
```

### 9.1.1 MCP Initialization Sequence

**CRITICAL**: The MCP protocol requires proper initialization before tool invocation.

```mermaid
sequenceDiagram
    participant App as hx-docling-ui
    participant MCP as hx-docling-mcp-server

    Note over App: Application startup

    App->>MCP: initialize { clientInfo, capabilities }
    MCP-->>App: { serverInfo, capabilities }

    App->>MCP: tools/list
    MCP-->>App: { tools: [...19 tools...] }

    Note over App: Cache tool schemas

    App->>MCP: tools/call { name, arguments }
    Note over App: Only after initialization!
    MCP-->>App: { result | error }
```

**Implementation**:
```typescript
// src/lib/mcp/client.ts
class MCPClient {
  private initialized = false;
  private toolRegistry: Map<string, MCPTool> = new Map();
  private serverCapabilities: ServerCapabilities | null = null;

  async initialize(): Promise<void> {
    if (this.initialized) return;

    // Step 1: Send initialize request
    const initResponse = await this.request({
      jsonrpc: '2.0',
      method: 'initialize',
      params: {
        clientInfo: {
          name: 'hx-docling-ui',
          version: process.env.NEXT_PUBLIC_APP_VERSION || '1.0.0',
        },
        capabilities: {
          tools: { listChanged: false },
        },
      },
      id: generateId(),
    });

    this.serverCapabilities = initResponse.capabilities;

    // Step 2: Discover available tools
    const toolsResponse = await this.request({
      jsonrpc: '2.0',
      method: 'tools/list',
      id: generateId(),
    });

    // Step 3: Cache tool schemas for client-side validation
    for (const tool of toolsResponse.tools) {
      this.toolRegistry.set(tool.name, tool);
    }

    this.initialized = true;
    console.log(`MCP client initialized with ${this.toolRegistry.size} tools`);
  }

  async invoke(toolName: string, params: unknown): Promise<unknown> {
    if (!this.initialized) {
      await this.initialize();
    }

    // Validate tool exists
    const tool = this.toolRegistry.get(toolName);
    if (!tool) {
      throw new MCPError('E204', `Unknown tool: ${toolName}`);
    }

    // Validate parameters against cached schema
    this.validateToolParams(tool, params);

    return this.request({
      jsonrpc: '2.0',
      method: 'tools/call',
      params: { name: toolName, arguments: params },
      id: generateId(),
    });
  }
}
```

### 9.1.2 JSON-RPC 2.0 Error Handling

**MCP Error Code Mapping**:
| JSON-RPC Code | MCP Meaning | App Error | User Message |
|---------------|-------------|-----------|--------------|
| `-32700` | Parse error | E203 | "Invalid request format" |
| `-32600` | Invalid Request | E203 | "Invalid request parameters" |
| `-32601` | Method not found | E204 | "Requested operation not available" |
| `-32602` | Invalid params | E203 | "Invalid input parameters" |
| `-32603` | Internal error | E201 | "Processing service error" |
| `-32000` to `-32099` | Server error | E201 | "Processing service unavailable" |

**Error Handler Implementation**:
```typescript
// src/lib/mcp/errors.ts
interface JSONRPCError {
  code: number;
  message: string;
  data?: unknown;
}

function handleMCPError(error: JSONRPCError): AppError {
  const errorMap: Record<number, { code: string; message: string }> = {
    [-32700]: { code: 'E203', message: 'Invalid request format' },
    [-32600]: { code: 'E203', message: 'Invalid request parameters' },
    [-32601]: { code: 'E204', message: 'Requested operation not available' },
    [-32602]: { code: 'E203', message: 'Invalid input parameters' },
    [-32603]: { code: 'E201', message: 'Processing service error' },
  };

  // Handle server error range (-32000 to -32099)
  if (error.code >= -32099 && error.code <= -32000) {
    return new AppError('E201', 'Processing service unavailable', {
      originalCode: error.code,
      originalMessage: error.message,
    });
  }

  const mapped = errorMap[error.code] || { code: 'E201', message: 'Unknown error' };
  return new AppError(mapped.code, mapped.message, {
    originalCode: error.code,
    originalMessage: error.message,
    data: error.data,
  });
}
```

### 9.1.3 Tool Registry and Schema Validation

**Tool Schema Cache**:
```typescript
// src/lib/mcp/schemas.ts
import { z } from 'zod';

// File path schema (common to all convert_* tools)
const FilePathSchema = z.object({
  file_path: z.string().min(1, 'File path required'),
  options: z.object({}).passthrough().optional(),
});

// URL schema for convert_url
const UrlSchema = z.object({
  url: z.string().url('Invalid URL format'),
  options: z.object({}).passthrough().optional(),
});

// DoclingDocument schema (opaque for Phase 1)
const DoclingDocumentSchema = z.object({}).passthrough();

// Export schema
const ExportSchema = z.object({
  document: DoclingDocumentSchema,
  options: z.object({}).passthrough().optional(),
});

// Tool parameter schemas
export const TOOL_SCHEMAS: Record<string, z.ZodSchema> = {
  'convert_pdf': FilePathSchema,
  'convert_docx': FilePathSchema,
  'convert_xlsx': FilePathSchema,
  'convert_pptx': FilePathSchema,
  'convert_url': UrlSchema,
  'export_markdown': ExportSchema,
  'export_html': ExportSchema,
  'export_json': ExportSchema,
};

// Validate tool parameters before invocation
export function validateToolParams(toolName: string, params: unknown): void {
  const schema = TOOL_SCHEMAS[toolName];
  if (!schema) {
    throw new AppError('E204', `Unknown tool: ${toolName}`);
  }

  const result = schema.safeParse(params);
  if (!result.success) {
    throw new AppError('E203', 'Invalid parameters', {
      errors: result.error.flatten(),
    });
  }
}
```

### 9.1.4 MCP Health Check

**Health Check Implementation**:
```typescript
// src/lib/mcp/health.ts
interface MCPHealthStatus {
  status: 'ok' | 'error' | 'timeout';
  latency: number;
  toolCount: number;
  message?: string;
  lastCheck: string;
}

async function checkMCPHealth(client: MCPClient): Promise<MCPHealthStatus> {
  const startTime = Date.now();

  try {
    // Lightweight health check - verify connection
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 2000);

    await fetch(`${MCP_ENDPOINT}/health`, {
      signal: controller.signal,
    });

    clearTimeout(timeout);

    return {
      status: 'ok',
      latency: Date.now() - startTime,
      toolCount: client.getToolCount(),
      lastCheck: new Date().toISOString(),
    };
  } catch (error) {
    if (error instanceof Error && error.name === 'AbortError') {
      return {
        status: 'timeout',
        latency: Date.now() - startTime,
        toolCount: 0,
        message: 'MCP server health check timed out',
        lastCheck: new Date().toISOString(),
      };
    }

    return {
      status: 'error',
      latency: Date.now() - startTime,
      toolCount: 0,
      message: error instanceof Error ? error.message : 'Unknown error',
      lastCheck: new Date().toISOString(),
    };
  }
}
```

#### MCP Tools (Phase 1 - 8 of 19)

| Tool | Purpose | Input | Output |
|------|---------|-------|--------|
| `convert_pdf` | Convert PDF documents | File path | DoclingDocument |
| `convert_docx` | Convert Word documents | File path | DoclingDocument |
| `convert_xlsx` | Convert Excel spreadsheets | File path | DoclingDocument |
| `convert_pptx` | Convert PowerPoint presentations | File path | DoclingDocument |
| `convert_url` | Convert web pages | URL | DoclingDocument |
| `export_markdown` | Export to Markdown | DoclingDocument | Markdown string |
| `export_html` | Export to HTML | DoclingDocument | HTML string |
| `export_json` | Export to JSON | DoclingDocument | JSON string |

**Reference**: Charter Section 8.2 - MCP Tools - Phase 1 Scope

### 9.2 SSE Streaming Pattern

**CRITICAL**: EventSource API cannot be used in Server Components. SSE connections MUST be established from Client Components via a Route Handler proxy.

#### 9.2.1 Correct SSE Architecture

```mermaid
sequenceDiagram
    participant Browser as Browser (Client Component)
    participant Hook as useSSE Hook
    participant RouteHandler as /api/v1/process/{jobId}/events
    participant MCP as MCP Server

    Note over Browser: Client Component mounts

    Browser->>Hook: useSSE(jobId)
    Hook->>RouteHandler: GET /api/v1/process/{jobId}/events
    Note over RouteHandler: Establish SSE to MCP

    RouteHandler->>MCP: Connect SSE stream

    loop Progress Events
        MCP-->>RouteHandler: Progress event
        RouteHandler-->>Hook: SSE: event: progress
        Hook-->>Browser: Update state
    end

    alt Network Interruption
        Note over Hook: Connection lost
        Hook->>Hook: Exponential backoff
        Hook->>RouteHandler: Reconnect with Last-Event-ID
        RouteHandler-->>Hook: Resume stream
    end

    alt SSE Unavailable
        Hook->>Hook: Detect SSE failure
        Hook->>RouteHandler: Fall back to polling
        loop Polling (2s interval)
            Hook->>RouteHandler: GET /api/v1/jobs/{jobId}
            RouteHandler-->>Hook: Current state
            Hook-->>Browser: Update UI
        end
    end

    MCP-->>RouteHandler: Complete
    RouteHandler-->>Hook: event: complete
    Hook-->>Browser: Show results
```

#### 9.2.2 Two-Endpoint SSE Design

**POST /api/v1/process** - Job initiation (returns immediately):
```typescript
// app/api/v1/process/route.ts
export async function POST(request: Request) {
  const { jobId, filePath, url } = await request.json();

  // Validate and queue job
  await prisma.job.update({
    where: { id: jobId },
    data: { status: 'PROCESSING' },
  });

  // Start MCP processing (non-blocking)
  processJobAsync(jobId, filePath || url);

  return NextResponse.json({
    jobId,
    streamUrl: `/api/v1/process/${jobId}/events`,
  });
}
```

**GET /api/v1/process/{jobId}/events** - SSE subscription:
```typescript
// app/api/v1/process/[jobId]/events/route.ts
export async function GET(
  request: Request,
  { params }: { params: { jobId: string } }
) {
  const { jobId } = params;

  // Verify job exists and is processing
  const job = await prisma.job.findUnique({ where: { id: jobId } });
  if (!job || job.status === 'COMPLETE') {
    return NextResponse.json({ error: 'Job not found or complete' }, { status: 404 });
  }

  // Create ReadableStream for SSE
  const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder();

      // Connect to MCP SSE endpoint
      const mcpStream = await fetch(`${MCP_ENDPOINT}/sse/${jobId}`);
      const reader = mcpStream.body?.getReader();

      if (!reader) {
        controller.close();
        return;
      }

      // Proxy MCP events to client
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        // Forward event to client
        controller.enqueue(value);
      }

      controller.close();
    },
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}
```

#### 9.2.3 Client-Side SSE Hook

**CRITICAL**: This hook MUST be in a Client Component with `'use client'` directive.

```typescript
// src/hooks/useSSE.ts
'use client';

import { useState, useEffect, useCallback, useRef } from 'react';

interface SSEConfig {
  maxRetries: number;
  backoffBase: number;
  backoffMax: number;
  pollingInterval: number;
}

const DEFAULT_CONFIG: SSEConfig = {
  maxRetries: 10,
  backoffBase: 1000,
  backoffMax: 30000,
  pollingInterval: 2000,
};

export function useSSE(jobId: string, config = DEFAULT_CONFIG) {
  const [progress, setProgress] = useState({ stage: 'initial', percent: 0 });
  const [connectionStatus, setConnectionStatus] = useState<'connected' | 'polling' | 'disconnected'>('disconnected');
  const [error, setError] = useState<Error | null>(null);
  const retryCount = useRef(0);
  const eventSourceRef = useRef<EventSource | null>(null);

  const connect = useCallback(() => {
    // Check SSE support
    if (typeof EventSource === 'undefined') {
      setConnectionStatus('polling');
      startPolling();
      return;
    }

    const eventSource = new EventSource(`/api/v1/process/${jobId}/events`);
    eventSourceRef.current = eventSource;

    eventSource.onopen = () => {
      setConnectionStatus('connected');
      retryCount.current = 0;
    };

    eventSource.addEventListener('progress', (event) => {
      const data = JSON.parse(event.data);
      setProgress(data);
    });

    eventSource.addEventListener('complete', (event) => {
      const data = JSON.parse(event.data);
      setProgress({ stage: 'complete', percent: 100, ...data });
      eventSource.close();
    });

    eventSource.onerror = () => {
      eventSource.close();

      if (retryCount.current < config.maxRetries) {
        retryCount.current++;
        const backoff = Math.min(
          config.backoffBase * Math.pow(2, retryCount.current - 1),
          config.backoffMax
        );
        setConnectionStatus('disconnected');
        setTimeout(connect, backoff);
      } else {
        // Fall back to polling
        setConnectionStatus('polling');
        startPolling();
      }
    };
  }, [jobId, config]);

  const startPolling = useCallback(() => {
    const poll = async () => {
      try {
        const response = await fetch(`/api/v1/jobs/${jobId}`);
        const data = await response.json();
        setProgress({
          stage: data.currentStage || 'processing',
          percent: data.currentPercent || 0,
        });

        if (data.status !== 'COMPLETE' && data.status !== 'ERROR') {
          setTimeout(poll, config.pollingInterval);
        }
      } catch (err) {
        setError(err as Error);
      }
    };

    poll();
  }, [jobId, config.pollingInterval]);

  useEffect(() => {
    connect();
    return () => {
      eventSourceRef.current?.close();
    };
  }, [connect]);

  return { progress, connectionStatus, error };
}
```

#### 9.2.4 Progress Interpolation

**Formula for smooth progress updates**:
```typescript
// src/lib/sse/progress.ts

interface ProgressInterpolation {
  currentPercent: number;
  previousPercent: number;
  targetPercent: number;
  lastUpdateTime: number;
}

// Interpolate MCP progress to UI progress
export function interpolateProgress(
  mcpPercent: number,
  rangeStart: number,
  rangeEnd: number
): number {
  return Math.floor(rangeStart + (mcpPercent / 100) * (rangeEnd - rangeStart));
}

// Smooth progress animation
export function smoothProgress(
  state: ProgressInterpolation,
  targetPercent: number,
  duration: number = 500
): void {
  const startTime = performance.now();
  const startPercent = state.currentPercent;

  function animate(currentTime: number) {
    const elapsed = currentTime - startTime;
    const progress = Math.min(elapsed / duration, 1);

    // Ease-out curve
    const eased = 1 - Math.pow(1 - progress, 3);

    state.currentPercent = Math.floor(startPercent + (targetPercent - startPercent) * eased);

    // Never go backwards
    state.currentPercent = Math.max(state.currentPercent, state.previousPercent);

    if (progress < 1) {
      requestAnimationFrame(animate);
    } else {
      state.previousPercent = state.currentPercent;
    }
  }

  requestAnimationFrame(animate);
}

// Debounce rapid updates (100ms)
export function debounceProgress(
  callback: (percent: number) => void,
  delay: number = 100
) {
  let timeoutId: NodeJS.Timeout;
  let lastPercent = 0;

  return (percent: number) => {
    // Never show backwards progress
    if (percent < lastPercent) return;

    lastPercent = percent;
    clearTimeout(timeoutId);
    timeoutId = setTimeout(() => callback(percent), delay);
  };
}
```

**Reference**: Charter Section 6.8 - SSE Resilience Strategy

### 9.3 Database Integration Pattern

```typescript
// Singleton Prisma Client Pattern
// Reference: Charter Section 12.3.1

import { PrismaClient } from '@prisma/client';

const globalForPrisma = globalThis as unknown as {
  prisma: PrismaClient | undefined;
};

export const prisma =
  globalForPrisma.prisma ??
  new PrismaClient({
    log: process.env.NODE_ENV === 'development'
      ? ['query', 'error', 'warn']
      : ['error'],
  });

if (process.env.NODE_ENV !== 'production') {
  globalForPrisma.prisma = prisma;
}
```

### 9.4 Redis Integration Pattern

#### 9.4.1 Redis Configuration with Authentication

**Environment Configuration**:
```env
# Redis connection with authentication
REDIS_URL=redis://:${REDIS_PASSWORD}@hx-redis-server.hx.dev.local:6379/0
REDIS_PASSWORD=<secure-password-from-vault>
```

**ioredis Client Configuration**:
```typescript
// src/lib/redis/client.ts
import Redis from 'ioredis';

const redisConfig = {
  host: process.env.REDIS_HOST || 'hx-redis-server.hx.dev.local',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD,
  db: 0,

  // Connection pooling
  maxRetriesPerRequest: 3,
  retryDelayOnFailover: 100,
  retryDelayOnClusterDown: 100,

  // Keep-alive
  keepAlive: 30000,

  // Timeouts
  connectTimeout: 10000,
  commandTimeout: 5000,

  // Reconnection
  reconnectOnError: (err) => {
    const targetErrors = ['READONLY', 'ECONNRESET'];
    return targetErrors.some(e => err.message.includes(e));
  },
};

// Singleton pattern
const globalForRedis = globalThis as unknown as {
  redis: Redis | undefined;
};

export const redis =
  globalForRedis.redis ?? new Redis(redisConfig);

if (process.env.NODE_ENV !== 'production') {
  globalForRedis.redis = redis;
}

// Health check
export async function checkRedisHealth(): Promise<{
  status: 'ok' | 'error';
  latency: number;
}> {
  const start = Date.now();
  try {
    await redis.ping();
    return { status: 'ok', latency: Date.now() - start };
  } catch {
    return { status: 'error', latency: Date.now() - start };
  }
}
```

#### 9.4.2 Redis Key Naming Convention

| Key Pattern | Purpose | TTL | Example |
|-------------|---------|-----|---------|
| `hx-docling:session:{uuid}` | Session data | 24h | `hx-docling:session:abc123` |
| `hx-docling:rate:{sessionId}` | Rate limiting | 60s | `hx-docling:rate:abc123` |
| `hx-docling:job:{jobId}:progress` | Job progress cache | 5m | `hx-docling:job:xyz789:progress` |

#### 9.4.3 Redis-Based Rate Limiting

**CRITICAL**: Rate limiting MUST use Redis, not in-memory Map, to support distributed deployment.

```typescript
// src/lib/redis/rate-limit.ts
import { redis } from './client';

interface RateLimitResult {
  allowed: boolean;
  remaining: number;
  retryAfter?: number;
}

const RATE_LIMIT_MAX = parseInt(process.env.RATE_LIMIT_MAX || '10');
const RATE_LIMIT_WINDOW = parseInt(process.env.RATE_LIMIT_WINDOW_MS || '60000') / 1000;

export async function checkRateLimit(sessionId: string): Promise<RateLimitResult> {
  const key = `hx-docling:rate:${sessionId}`;

  // Use Redis INCR with EXPIRE (fixed window algorithm)
  const current = await redis.incr(key);

  if (current === 1) {
    // First request in window - set expiry
    await redis.expire(key, RATE_LIMIT_WINDOW);
  }

  const ttl = await redis.ttl(key);

  if (current > RATE_LIMIT_MAX) {
    return {
      allowed: false,
      remaining: 0,
      retryAfter: ttl > 0 ? ttl : RATE_LIMIT_WINDOW,
    };
  }

  return {
    allowed: true,
    remaining: RATE_LIMIT_MAX - current,
  };
}

// Middleware integration
export async function rateLimitMiddleware(
  sessionId: string
): Promise<{ pass: true } | { pass: false; response: Response }> {
  const result = await checkRateLimit(sessionId);

  if (!result.allowed) {
    return {
      pass: false,
      response: new Response(
        JSON.stringify({
          error: 'E601',
          message: 'Rate limit exceeded',
          retryAfter: result.retryAfter,
        }),
        {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'Retry-After': String(result.retryAfter),
            'X-RateLimit-Limit': String(RATE_LIMIT_MAX),
            'X-RateLimit-Remaining': '0',
            // Unix timestamp in seconds (not milliseconds) per RFC 9238
            'X-RateLimit-Reset': String(Math.floor(Date.now() / 1000) + (result.retryAfter || 60)),
          },
        }
      ),
    };
  }

  return { pass: true };
}
```

---

## 10. Security Architecture

### 10.1 Security Model Overview

```mermaid
flowchart TB
    subgraph External["External Layer"]
        User[User Browser]
    end

    subgraph EdgeSecurity["Edge Security"]
        RL[Rate Limiting<br/>10 req/min per session]
        IV[Input Validation<br/>Zod schemas]
        SSRF[SSRF Protection<br/>URL blocking]
    end

    subgraph SessionSecurity["Session Security"]
        Cookie[Session Cookie<br/>UUID, 24h TTL]
        Redis[Redis Session Store]
    end

    subgraph DataSecurity["Data Security"]
        Prisma[Parameterized Queries<br/>Prisma ORM]
        SSL[SSL/TLS<br/>PostgreSQL connection]
        FS[File Permissions<br/>0640]
    end

    User --> RL
    RL --> IV
    IV --> SSRF
    SSRF --> Cookie
    Cookie --> Redis
    Redis --> Prisma
    Prisma --> SSL
    SSL --> FS
```

### 10.2 Security Controls

| Control | Implementation | Reference |
|---------|----------------|-----------|
| **Rate Limiting** | 10 req/min per session, 429 response | Charter Section 8.1.1 |
| **Input Validation** | Zod schemas for file and URL validation | Charter Section 11.2, 11.3 |
| **SSRF Prevention** | Block private IPs, internal domains | Charter Section 11.3 |
| **Session Tracking** | UUID cookie, Redis with 24h TTL | Charter Section 7.4 |
| **SQL Injection** | Parameterized queries via Prisma | Charter Section 11.1 |
| **File Security** | 0640 permissions, dedicated user | Charter Section 7.5.1 |
| **Network Isolation** | hx.dev.local internal network only | Charter Section 14.1 |

### 10.3 URL Security Implementation

```typescript
// SSRF Prevention
// Reference: Charter Section 11.3

const urlSchema = z.string()
  .url({ message: 'Invalid URL format' })
  .max(2048, { message: 'URL too long (max 2048 characters)' })
  .refine(url => {
    const parsed = new URL(url);

    // Protocol validation: HTTP/HTTPS only
    if (!['http:', 'https:'].includes(parsed.protocol)) {
      return false;
    }

    const hostname = parsed.hostname.toLowerCase();

    // Block localhost
    if (hostname === 'localhost' || hostname === '127.0.0.1') {
      return false;
    }

    // Block private IP ranges (RFC 1918)
    const ipv4Pattern = /^(\d{1,3}\.){3}\d{1,3}$/;
    if (ipv4Pattern.test(hostname)) {
      const parts = hostname.split('.').map(Number);
      if (parts[0] === 10) return false;                    // 10.0.0.0/8
      if (parts[0] === 172 && parts[1] >= 16 && parts[1] <= 31) return false;  // 172.16.0.0/12
      if (parts[0] === 192 && parts[1] === 168) return false;  // 192.168.0.0/16
      if (parts[0] === 169 && parts[1] === 254) return false;  // 169.254.0.0/16
    }

    // Block internal HX domains
    if (hostname.endsWith('.hx.dev.local')) {
      return false;
    }

    return true;
  }, { message: 'URL not allowed (internal or private address)' });
```

---

## 11. Error Handling and Resilience

### 11.1 Error Recovery Strategy

```mermaid
stateDiagram-v2
    [*] --> Processing: Start MCP call

    Processing --> Success: MCP returns result
    Processing --> TransientError: Timeout, 5xx, network error
    Processing --> FatalError: 4xx, validation error

    TransientError --> Retry1: Attempt 1
    Retry1 --> Processing: Wait 1s, retry
    Retry1 --> Retry2: Still failing

    Retry2 --> Processing: Wait 2s, retry
    Retry2 --> Retry3: Still failing

    Retry3 --> Processing: Wait 4s, retry
    Retry3 --> ExhaustedError: All retries failed

    Success --> ExportMarkdown: Convert complete
    ExportMarkdown --> ExportHtml: MD success
    ExportMarkdown --> PartialResult: MD failed

    ExportHtml --> ExportJson: HTML success
    ExportHtml --> PartialResult: HTML failed

    ExportJson --> Complete: JSON success
    ExportJson --> PartialResult: JSON failed

    PartialResult --> Complete: Save available results

    FatalError --> [*]: Show error, allow retry
    ExhaustedError --> [*]: Show error, allow retry
    Complete --> [*]: Show results
```

**Reference**: Charter Section 8.6 - MCP Error Recovery Strategy

### 11.2 Error Catalog Summary

| Category | Code Range | Examples |
|----------|------------|----------|
| **File Errors** | E0xx | E001 (too large), E002 (unsupported format) |
| **URL Errors** | E1xx | E101 (invalid URL), E104 (blocked) |
| **MCP Errors** | E2xx | E201 (unavailable), E202 (timeout) |
| **Processing Errors** | E3xx | E301 (timeout), E304 (partial export) |
| **Database Errors** | E4xx | E401 (connection), E403 (persist failed) |
| **Session Errors** | E5xx | E501 (expired), E502 (invalid) |
| **Rate Limiting** | E6xx | E601 (rate limit exceeded) |
| **Network Errors** | E9xx | E901 (network error), E903 (SSE reconnect failed) |

**Reference**: Charter Appendix A - Error Catalog with Recovery

### 11.2.1 Error UI Mapping

The ErrorDisplay component renders different error types with distinct visual feedback:

| Error Category | UI Variant | Color | Icon | Primary Action |
|----------------|------------|-------|------|----------------|
| File Errors (E0xx) | `ErrorDisplay.FileError` | Orange | FileX | "Try Different File" |
| URL Errors (E1xx) | `ErrorDisplay.UrlError` | Orange | LinkBreak | "Correct URL" |
| MCP Errors (E2xx) | `ErrorDisplay.ServiceError` | Red | ServerCrash | "Retry" |
| Processing (E3xx) | `ErrorDisplay.ProcessingError` | Yellow | Clock | "Retry" |
| Database (E4xx) | `ErrorDisplay.SystemError` | Red | Database | "Contact Support" |
| Session (E5xx) | `ErrorDisplay.SessionError` | Blue | RefreshCw | "Refresh Page" |
| Rate Limit (E6xx) | `ErrorDisplay.RateLimit` | Yellow | Timer | "Wait X seconds" |
| Network (E9xx) | `ErrorDisplay.NetworkError` | Gray | WifiOff | "Check Connection" |

**Component Implementation**:
```typescript
// src/components/error/ErrorDisplay.tsx
'use client';

import { AlertCircle, FileX, LinkBreak, ServerCrash, Clock, Database, RefreshCw, Timer, WifiOff } from 'lucide-react';
import { Alert, AlertDescription, AlertTitle } from '@/components/ui/alert';
import { Button } from '@/components/ui/button';

interface ErrorDisplayProps {
  error: AppError;
  onRetry?: () => void;
  onDismiss?: () => void;
}

const ERROR_CONFIG: Record<string, {
  icon: typeof AlertCircle;
  variant: 'default' | 'destructive';
  primaryAction: string;
}> = {
  'E0': { icon: FileX, variant: 'default', primaryAction: 'Try Different File' },
  'E1': { icon: LinkBreak, variant: 'default', primaryAction: 'Correct URL' },
  'E2': { icon: ServerCrash, variant: 'destructive', primaryAction: 'Retry' },
  'E3': { icon: Clock, variant: 'default', primaryAction: 'Retry' },
  'E4': { icon: Database, variant: 'destructive', primaryAction: 'Contact Support' },
  'E5': { icon: RefreshCw, variant: 'default', primaryAction: 'Refresh Page' },
  'E6': { icon: Timer, variant: 'default', primaryAction: 'Wait' },
  'E9': { icon: WifiOff, variant: 'default', primaryAction: 'Check Connection' },
};

export function ErrorDisplay({ error, onRetry, onDismiss }: ErrorDisplayProps) {
  const prefix = error.code.substring(0, 2);
  const config = ERROR_CONFIG[prefix] || { icon: AlertCircle, variant: 'destructive', primaryAction: 'Retry' };
  const Icon = config.icon;

  return (
    <Alert variant={config.variant} role="alert" aria-live="assertive">
      <Icon className="h-4 w-4" />
      <AlertTitle>Error {error.code}</AlertTitle>
      <AlertDescription>
        <p>{error.message}</p>
        {error.recovery && (
          <p className="text-sm text-muted-foreground mt-1">{error.recovery}</p>
        )}
        <div className="flex gap-2 mt-4">
          {error.retryable && onRetry && (
            <Button onClick={onRetry} size="sm">
              {config.primaryAction}
            </Button>
          )}
          {onDismiss && (
            <Button onClick={onDismiss} variant="ghost" size="sm">
              Dismiss
            </Button>
          )}
        </div>
      </AlertDescription>
    </Alert>
  );
}
```

### 11.3 SSE Reconnection Configuration

```typescript
// SSE Resilience Configuration
// Reference: Charter Section 6.8

// Type definitions for SSE configuration
interface SSEConfig {
  maxRetries: number;
  backoffStrategy: 'exponential' | 'linear';
  backoffBase: number;        // milliseconds
  backoffMax: number;         // milliseconds
  backoffMultiplier: number;
  gracePeriod: number;        // milliseconds
  fallbackToPolling: boolean;
  pollingInterval: number;    // milliseconds
}

// Default configuration values
const SSE_CONFIG_DEFAULTS: SSEConfig = {
  maxRetries: 10,
  backoffStrategy: 'exponential',
  backoffBase: 1000,          // 1 second
  backoffMax: 30000,          // 30 seconds max
  backoffMultiplier: 2,       // 1s -> 2s -> 4s -> 8s -> 16s -> 30s
  gracePeriod: 30000,         // 30 seconds total
  fallbackToPolling: true,
  pollingInterval: 2000,      // 2 seconds
};
```

---

## 12. Scalability Considerations

### 12.1 Current Capacity (Phase 1)

| Resource | Capacity | Constraint |
|----------|----------|------------|
| Concurrent users | ~10 | Development server, single instance |
| File storage | 500 GB | /data partition |
| Database connections | 100 | PostgreSQL max_connections |
| Rate limit | 10 req/min per session | Application enforced |
| Max file size | 100 MB | MCP server limit |
| Processing timeout | 300 seconds | Large documents |

### 12.2 Scaling Considerations (Future)

| Aspect | Current | Future Consideration |
|--------|---------|---------------------|
| **Horizontal Scaling** | Single instance | Multiple instances behind load balancer |
| **Database Pooling** | 5 connections per instance | PgBouncer for connection pooling |
| **File Storage** | Local disk | NFS or S3-compatible object storage |
| **Session Affinity** | Not required (Redis-backed) | Sticky sessions optional |
| **Job Queue** | Synchronous | Redis-based job queue for async processing |

### 12.3 Performance Targets

| Metric | Target | Reference |
|--------|--------|-----------|
| LCP (Largest Contentful Paint) | < 2.5s | Charter Section 5.2 |
| FCP (First Contentful Paint) | < 1.8s | Charter Section 5.2 |
| Time to first SSE event | < 500ms | Charter Section 5.2 |
| SSE reconnection | < 30s | Charter Section 5.3 |
| Processing (< 10 MB) | < 60s | Charter Section 8.1.2 |
| Processing (50-100 MB) | < 300s | Charter Section 8.1.2 |

### 12.4 State Machine Checkpointing

**Purpose**: If the application crashes during document processing, checkpointing allows resumption from the last successful stage.

**Checkpoint Strategy (Phase 1)**:
```typescript
// src/lib/checkpoint/manager.ts
import { prisma } from '@/lib/db/prisma';

interface Checkpoint {
  jobId: string;
  stage: ProcessingStage;
  data: unknown;
  createdAt: Date;
}

type ProcessingStage =
  | 'uploaded'
  | 'converted'
  | 'export_markdown'
  | 'export_html'
  | 'export_json'
  | 'complete';

// Save checkpoint after each major stage
async function saveCheckpoint(jobId: string, stage: ProcessingStage, data: unknown): Promise<void> {
  await prisma.job.update({
    where: { id: jobId },
    data: {
      currentStage: stage,
      // Store DoclingDocument after conversion for resume capability
      ...(stage === 'converted' && {
        checkpointData: JSON.stringify(data),
      }),
    },
  });
}

// Resume processing from last checkpoint
async function resumeFromCheckpoint(jobId: string): Promise<{
  stage: ProcessingStage;
  data: unknown;
} | null> {
  const job = await prisma.job.findUnique({
    where: { id: jobId },
    select: { currentStage: true, checkpointData: true },
  });

  if (!job?.currentStage) return null;

  return {
    stage: job.currentStage as ProcessingStage,
    data: job.checkpointData ? JSON.parse(job.checkpointData) : null,
  };
}
```

**Checkpoint Flow**:
```mermaid
flowchart TD
    Upload[Upload Complete] --> CP1[Checkpoint: uploaded]
    CP1 --> Convert[Convert Document]
    Convert --> CP2[Checkpoint: converted<br/>Save DoclingDocument]
    CP2 --> ExportMD[Export Markdown]
    ExportMD --> CP3[Checkpoint: export_markdown]
    CP3 --> ExportHTML[Export HTML]
    ExportHTML --> CP4[Checkpoint: export_html]
    CP4 --> ExportJSON[Export JSON]
    ExportJSON --> CP5[Checkpoint: complete]

    subgraph Recovery["On Restart"]
        Load[Load Last Checkpoint] --> Resume{Stage?}
        Resume -->|converted| ExportMD
        Resume -->|export_markdown| ExportHTML
        Resume -->|export_html| ExportJSON
    end
```

**Note**: Full LangGraph-style durable execution with persistent task queues is a Phase 2+ enhancement.

### 12.5 Circuit Breaker Pattern

**Purpose**: Prevent cascading failures when the MCP server is unhealthy.

```typescript
// src/lib/mcp/circuit-breaker.ts
type CircuitState = 'closed' | 'open' | 'half-open';

interface CircuitBreakerConfig {
  failureThreshold: number;  // Failures before opening
  resetTimeout: number;      // Cooldown in ms
  halfOpenRequests: number;  // Test requests in half-open
}

const DEFAULT_CONFIG: CircuitBreakerConfig = {
  failureThreshold: 5,
  resetTimeout: 60000,       // 60 seconds
  halfOpenRequests: 3,
};

class CircuitBreaker {
  private state: CircuitState = 'closed';
  private failures = 0;
  private lastFailureTime = 0;
  private halfOpenSuccesses = 0;

  constructor(private config = DEFAULT_CONFIG) {}

  async execute<T>(operation: () => Promise<T>): Promise<T> {
    // Check if circuit should transition from open to half-open
    if (this.state === 'open') {
      if (Date.now() - this.lastFailureTime >= this.config.resetTimeout) {
        this.state = 'half-open';
        this.halfOpenSuccesses = 0;
        console.log('Circuit breaker: transitioning to half-open');
      } else {
        throw new CircuitOpenError('Circuit breaker is open');
      }
    }

    try {
      const result = await operation();

      // Success handling
      if (this.state === 'half-open') {
        this.halfOpenSuccesses++;
        if (this.halfOpenSuccesses >= this.config.halfOpenRequests) {
          this.state = 'closed';
          this.failures = 0;
          console.log('Circuit breaker: closing after successful half-open');
        }
      } else {
        this.failures = 0;  // Reset on success
      }

      return result;
    } catch (error) {
      // Failure handling
      this.failures++;
      this.lastFailureTime = Date.now();

      if (this.state === 'half-open') {
        this.state = 'open';
        console.log('Circuit breaker: reopening after half-open failure');
      } else if (this.failures >= this.config.failureThreshold) {
        this.state = 'open';
        console.log(`Circuit breaker: opening after ${this.failures} failures`);
      }

      throw error;
    }
  }

  getState(): CircuitState {
    return this.state;
  }

  isAvailable(): boolean {
    if (this.state === 'open') {
      return Date.now() - this.lastFailureTime >= this.config.resetTimeout;
    }
    return true;
  }
}

class CircuitOpenError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'CircuitOpenError';
  }
}

// Global circuit breaker for MCP client
export const mcpCircuitBreaker = new CircuitBreaker();

// Usage in MCP client
async function invokeToolWithCircuitBreaker(
  toolName: string,
  params: unknown
): Promise<unknown> {
  return mcpCircuitBreaker.execute(() =>
    mcpClient.invoke(toolName, params)
  );
}
```

**Integration with Health Check**:
```typescript
// Include circuit breaker state in health check
interface HealthCheckResponse {
  status: 'healthy' | 'degraded' | 'unhealthy';
  // ...
  circuitBreaker: {
    state: CircuitState;
    failures: number;
    lastFailure: string | null;
  };
}
```

---

## 13. Deployment Architecture

### 13.1 Phase 1 Deployment (Development)

```
+----------------------------------------------------------+
|                   hx-cc-server                            |
|                   192.168.10.224                          |
|                                                           |
|  +----------------------------------------------------+  |
|  |              Node.js 20.x (Bare Metal)             |  |
|  |                                                    |  |
|  |  +----------------------------------------------+ |  |
|  |  |           Next.js 16 Dev Server              | |  |
|  |  |           npm run dev --turbopack            | |  |
|  |  |           Port: 3000                         | |  |
|  |  +----------------------------------------------+ |  |
|  |                                                    |  |
|  |  Environment:                                      |  |
|  |  - .env.development                               |  |
|  |  - No SSL (internal network)                      |  |
|  |  - systemd service management                     |  |
|  |                                                    |  |
|  +----------------------------------------------------+  |
|                                                           |
|  File Storage: /data/docling-uploads/                    |
|                                                           |
+----------------------------------------------------------+
```

### 13.1.1 systemd Service Configuration

**Phase 1 Development** - Service runs as `agent0` user on hx-cc-server for development:

**Service Unit File** (`/etc/systemd/system/hx-docling-ui.service`):
```ini
[Unit]
Description=HX Docling UI Application (Phase 1 Development)
Documentation=https://github.com/hx-infrastructure/hx-docling-application
After=network.target

[Service]
Type=simple
# Phase 1: Run as agent0 user (development environment)
User=agent0
Group=agent0
WorkingDirectory=/home/agent0/hx-docling-ui

# Environment - Phase 1 Development
Environment=NODE_ENV=development
Environment=PORT=3000
EnvironmentFile=/home/agent0/hx-docling-ui/.env

# Execution - Development mode with npm
ExecStart=/usr/bin/npm run dev
ExecReload=/bin/kill -HUP $MAINPID

# Restart policy
Restart=on-failure
RestartSec=10
StartLimitInterval=60
StartLimitBurst=3

# Resource limits (cgroups v2)
MemoryMax=2G
CPUQuota=200%

# Graceful shutdown
TimeoutStopSec=30
KillMode=mixed
KillSignal=SIGTERM

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=hx-docling-ui

# Security (relaxed for development)
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

**Phase 2 Production** - Service runs as dedicated `docling` user with standalone build:

```ini
[Unit]
Description=HX Docling UI Application (Phase 2 Production)
Documentation=https://github.com/hx-infrastructure/hx-docling-application
After=network.target

[Service]
Type=simple
# Phase 2: Run as dedicated docling user
User=docling
Group=docling
WorkingDirectory=/opt/hx-docling-ui

# Environment - Production
Environment=NODE_ENV=production
Environment=PORT=3000
EnvironmentFile=/opt/hx-docling-ui/.env.production

# Execution - Standalone server.js
ExecStart=/usr/bin/node /opt/hx-docling-ui/.next/standalone/server.js
ExecReload=/bin/kill -HUP $MAINPID

# Restart policy
Restart=on-failure
RestartSec=10
StartLimitInterval=60
StartLimitBurst=3

# Resource limits (cgroups v2)
MemoryMax=2G
CPUQuota=200%

# Graceful shutdown (300s for MCP timeout + 30s buffer)
TimeoutStopSec=330
KillMode=mixed
KillSignal=SIGTERM

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=hx-docling-ui

# Security hardening (production)
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/data/docling-uploads /tmp/docling-processing /var/log/hx-docling-ui

[Install]
WantedBy=multi-user.target
```

**Pre-deployment Setup** (Phase 2):
```bash
# Create docling user and directories
sudo useradd -r -s /bin/false docling
sudo mkdir -p /opt/hx-docling-ui /data/docling-uploads /var/log/hx-docling-ui
sudo chown -R docling:docling /opt/hx-docling-ui /data/docling-uploads /var/log/hx-docling-ui
sudo chmod 750 /opt/hx-docling-ui

# Copy env file with restricted permissions
sudo cp .env.production /opt/hx-docling-ui/.env.production
sudo chown docling:docling /opt/hx-docling-ui/.env.production
sudo chmod 600 /opt/hx-docling-ui/.env.production
```

**Service Management Commands**:
```bash
# Enable service to start on boot
sudo systemctl enable hx-docling-ui

# Start service
sudo systemctl start hx-docling-ui

# Check status
sudo systemctl status hx-docling-ui

# View logs
sudo journalctl -u hx-docling-ui -f

# Reload after config change
sudo systemctl reload hx-docling-ui

# Restart service
sudo systemctl restart hx-docling-ui
```

### 13.1.2 Graceful Shutdown Handling

**Node.js Signal Handling**:
```typescript
// src/lib/shutdown.ts
import { prisma } from '@/lib/db/prisma';
import { redis } from '@/lib/redis/client';

const SHUTDOWN_TIMEOUT = 30000; // 30 seconds
let isShuttingDown = false;

export function setupGracefulShutdown(): void {
  const shutdown = async (signal: string) => {
    if (isShuttingDown) return;
    isShuttingDown = true;

    console.log(`Received ${signal}, starting graceful shutdown...`);

    // Set health check to unhealthy
    setHealthStatus('draining');

    // Wait for in-flight requests to complete
    const drainTimeout = setTimeout(() => {
      console.warn('Drain timeout exceeded, forcing shutdown');
      process.exit(1);
    }, SHUTDOWN_TIMEOUT);

    try {
      // Close database connections
      await prisma.$disconnect();
      console.log('Database connections closed');

      // Close Redis connections
      await redis.quit();
      console.log('Redis connections closed');

      clearTimeout(drainTimeout);
      console.log('Graceful shutdown complete');
      process.exit(0);
    } catch (error) {
      console.error('Error during shutdown:', error);
      process.exit(1);
    }
  };

  process.on('SIGTERM', () => shutdown('SIGTERM'));
  process.on('SIGINT', () => shutdown('SIGINT'));
  process.on('SIGHUP', () => shutdown('SIGHUP'));
}

// Track active requests
let activeRequests = 0;

export function incrementRequests(): void {
  activeRequests++;
}

export function decrementRequests(): void {
  activeRequests--;
}

export function getActiveRequests(): number {
  return activeRequests;
}
```

### 13.2 Environment Configuration

```env
# .env.development
NODE_ENV=development

# MCP Server
DOCLING_MCP_URL=http://hx-docling-mcp-server.hx.dev.local:8000/mcp
DOCLING_MCP_TIMEOUT_SMALL=60000
DOCLING_MCP_TIMEOUT_MEDIUM=180000
DOCLING_MCP_TIMEOUT_LARGE=300000

# File Upload
MAX_FILE_SIZE_MB=100
ALLOWED_FILE_TYPES=.pdf,.docx,.doc,.pptx,.ppt,.xlsx,.xls,.png,.jpg,.jpeg,.tiff
TEMP_STORAGE_PATH=/tmp/docling-processing
PERSISTENT_STORAGE_PATH=/data/docling-uploads

# PostgreSQL (via PgBouncer)
DATABASE_URL=postgresql://docling_app:${DB_PASSWORD}@hx-postgres-server.hx.dev.local:6432/docling_db?sslmode=require
DIRECT_DATABASE_URL=postgresql://docling_migration:${MIGRATION_PASSWORD}@hx-postgres-server.hx.dev.local:5432/docling_db?sslmode=require

# Redis (with authentication)
REDIS_URL=redis://:${REDIS_PASSWORD}@hx-redis-server.hx.dev.local:6379/0
REDIS_PASSWORD=${REDIS_PASSWORD}

# Rate Limiting
RATE_LIMIT_MAX=10
RATE_LIMIT_WINDOW_MS=60000

# Application
NEXT_PUBLIC_APP_VERSION=1.0.0-dev
```

**Reference**: Charter Section 8.3 - Environment Configuration

### 13.3 Setup Commands

```bash
# On hx-cc-server (192.168.10.224)

# 1. Navigate to project directory
cd /home/agent0/hx-docling-ui

# 2. Install dependencies
npm install

# 3. Create environment file
cp .env.example .env.development

# 4. Generate Prisma client
npx prisma generate

# 5. Run database migrations
npx prisma migrate dev --name initial_schema

# 6. Start development server
npm run dev
```

**Reference**: Charter Section 12.3 - Setup Commands

### 13.4 Disaster Recovery

#### 13.4.1 Application Recovery Procedure

**Recovery Time Objective (RTO)**: 4 hours

**Recovery Sources**:
| Component | Source | Location |
|-----------|--------|----------|
| Application code | Git repository | GitHub/GitLab |
| Dependencies | npm registry | `package-lock.json` |
| Environment variables | Ansible Vault | `/etc/ansible/vault/hx-docling-ui.yml` |
| Database schema | Prisma migrations | `prisma/migrations/` |
| systemd service | Ansible playbook | `ansible/roles/hx-docling-ui/` |

**Step-by-Step Recovery Runbook**:

```bash
# 1. Provision new server (if needed)
# Ensure Node.js >= 20.9.0 is installed (Next.js 16 requirement)

# 2. Clone repository
git clone https://github.com/hx-infrastructure/hx-docling-application.git /home/agent0/hx-docling-ui
cd /home/agent0/hx-docling-ui

# 3. Restore environment file from Ansible Vault
ansible-vault decrypt /etc/ansible/vault/hx-docling-ui.yml --output=/etc/hx-docling-ui/env

# 4. Install dependencies (reproducible from lock file)
npm ci --production

# 5. Generate Prisma client
npx prisma generate

# 6. Verify database connection and run any pending migrations
npx prisma migrate deploy

# 7. Build application
npm run build

# 8. Install and start systemd service
sudo cp /home/agent0/hx-docling-ui/deploy/hx-docling-ui.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable hx-docling-ui
sudo systemctl start hx-docling-ui

# 9. Verify application is healthy
curl http://localhost:3000/api/health
```

**Data Recovery**:
- Job history: Recovered from PostgreSQL backups (daily, 7-day retention)
- Uploaded files: Not recoverable if lost (users can re-upload)
- Sessions: Regenerated on user reconnection (no recovery needed)

**Testing Recovery Procedure**: Quarterly (schedule with operations team)

### 13.5 Health Check Alerting Integration

**Option A: Prometheus /metrics Endpoint** (Recommended)

Add a dedicated `/api/v1/metrics` endpoint that exports Prometheus text format:

```typescript
// app/api/v1/metrics/route.ts
import { NextResponse } from 'next/server';
import { prisma } from '@/lib/prisma';
import { redis } from '@/lib/redis';

export async function GET() {
  const [dbHealthy, redisHealthy, mcpHealthy] = await Promise.all([
    prisma.$queryRaw`SELECT 1`.then(() => 1).catch(() => 0),
    redis.ping().then(() => 1).catch(() => 0),
    fetch(`${process.env.DOCLING_MCP_ORIGIN}/health`).then(r => r.ok ? 1 : 0).catch(() => 0),
  ]);

  const metrics = `
# HELP hx_docling_ui_health Overall application health (1=healthy, 0=unhealthy)
# TYPE hx_docling_ui_health gauge
hx_docling_ui_health{service="docling-ui"} ${dbHealthy && redisHealthy && mcpHealthy ? 1 : 0}

# HELP hx_docling_ui_dependency_health Dependency health status
# TYPE hx_docling_ui_dependency_health gauge
hx_docling_ui_dependency_health{dependency="postgresql"} ${dbHealthy}
hx_docling_ui_dependency_health{dependency="redis"} ${redisHealthy}
hx_docling_ui_dependency_health{dependency="mcp"} ${mcpHealthy}
`.trim();

  return new NextResponse(metrics, {
    headers: { 'Content-Type': 'text/plain; charset=utf-8' },
  });
}
```

**Prometheus Scrape Configuration** (using /metrics):
```yaml
# prometheus/scrape_configs.yml
scrape_configs:
  - job_name: 'hx-docling-ui'
    metrics_path: '/api/v1/metrics'
    static_configs:
      - targets: ['hx-cc-server.hx.dev.local:3000']
    scrape_interval: 30s
    scrape_timeout: 10s
```

---

**Option B: Blackbox Exporter** (Alternative - probes JSON /api/health)

If you prefer to keep `/api/health` as JSON-only, use blackbox_exporter to probe it:

```yaml
# prometheus/scrape_configs.yml
scrape_configs:
  # Blackbox exporter probes the JSON health endpoint
  - job_name: 'hx-docling-ui-probe'
    metrics_path: /probe
    params:
      module: [http_2xx_json]  # Custom module for JSON health check
    static_configs:
      - targets:
          - http://hx-cc-server.hx.dev.local:3000/api/v1/health
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: hx-prometheus-server.hx.dev.local:9115  # Blackbox exporter address
```

```yaml
# blackbox_exporter/config.yml
modules:
  http_2xx_json:
    prober: http
    timeout: 10s
    http:
      valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
      valid_status_codes: [200]
      method: GET
      headers:
        Accept: application/json
      fail_if_body_not_matches_regexp:
        - '"status":\s*"healthy"'
```

**Alertmanager Rules**:
```yaml
# alertmanager/rules/hx-docling-ui.yml
groups:
  - name: hx-docling-ui
    rules:
      - alert: DoclingUIUnhealthy
        expr: hx_docling_ui_health_status != 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "HX Docling UI is unhealthy"
          description: "Health check has been failing for 2 minutes"

      - alert: DoclingUIMCPUnavailable
        expr: hx_docling_ui_mcp_status != 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "MCP server connection issue"
          description: "Cannot connect to MCP server for 5 minutes"

      - alert: DoclingUIHighLatency
        expr: hx_docling_ui_health_latency_ms > 500
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High health check latency"
          description: "Health check latency exceeds 500ms"

      - alert: DoclingUICircuitOpen
        expr: hx_docling_ui_circuit_breaker_state == 2
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Circuit breaker is open"
          description: "MCP circuit breaker has opened due to repeated failures"
```

**Grafana Dashboard**:
- **Panel 1**: Health status (gauge: healthy/degraded/unhealthy)
- **Panel 2**: Component health (table: MCP, PostgreSQL, Redis, FileStorage)
- **Panel 3**: Response latency (graph: p50, p95, p99)
- **Panel 4**: Circuit breaker state (state timeline)
- **Panel 5**: Active connections (gauge)
- **Panel 6**: Error rate by code (bar chart)

**Notification Channels**:
| Alert Level | Channel | Responder |
|-------------|---------|-----------|
| Warning | Email + Slack | Development team |
| Critical | PagerDuty | On-call engineer |
| Emergency | Phone escalation | Platform architect |

---

## 14. Architecture Decision Records

### ADR-001: Next.js 16 with App Router

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need modern React framework with SSR and API routes. Architecture targets Next.js 16 as forward-looking design. |
| **Decision** | Use Next.js 16 with App Router |
| **Rationale** | Latest framework release, integrated Turbopack with improved performance, React 19+ support, built-in API routes, streaming SSE, Server Actions |
| **Consequences** | (+) Modern stack, fast builds, Server Actions for mutations (-) Learning curve for Server Components |

### ADR-002: Zustand for State Management

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need client-side state management for document workflow |
| **Decision** | Use Zustand 5.x |
| **Rationale** | Minimal footprint, SSR-ready, simple API |
| **Consequences** | (+) Less boilerplate (-) Less structured than Redux |

### ADR-003: SSE for Real-Time Progress

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need real-time progress updates during processing |
| **Decision** | Use Server-Sent Events with reconnection logic |
| **Rationale** | Native browser support, unidirectional fits use case |
| **Consequences** | (+) Simple, built-in reconnection (-) One-way only |

### ADR-004: PostgreSQL for Persistence

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need reliable data persistence for jobs and results |
| **Decision** | Use existing hx-postgres-server |
| **Rationale** | HX-Infrastructure standard, ACID compliance, operational |
| **Consequences** | (+) Existing infrastructure (-) Network dependency |

### ADR-005: Redis for Sessions and Rate Limiting

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need fast session management with TTL support and distributed rate limiting |
| **Decision** | Use existing hx-redis-server with authentication |
| **Rationale** | Fast, TTL support, already operational, supports distributed state for rate limiting |
| **Consequences** | (+) Existing infrastructure, distributed rate limiting (-) Adds dependency, requires password management |

### ADR-006: PgBouncer for Connection Pooling

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need connection pooling to support concurrent users without exhausting PostgreSQL connections |
| **Decision** | Use PgBouncer in transaction mode on hx-postgres-server |
| **Rationale** | Efficient connection reuse, supports ~10 concurrent users with 25 pooled connections, transaction mode works with Prisma |
| **Consequences** | (+) Better connection management, scalability (-) Additional component to maintain, port 6432 instead of 5432 |

### ADR-007: Server Actions for Mutations

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Need type-safe mutations without manual API route creation |
| **Decision** | Use React 19 Server Actions for job creation and status updates |
| **Rationale** | Type-safe, automatic form handling, progressive enhancement |
| **Consequences** | (+) Less boilerplate, type safety (-) New paradigm, requires `'use server'` directive |

### ADR-008: Redis-Based Rate Limiting

| Aspect | Details |
|--------|---------|
| **Status** | Accepted |
| **Context** | Rate limiting must work across multiple application instances |
| **Decision** | Implement rate limiting using Redis INCR/EXPIRE (fixed window) instead of in-memory Map |
| **Rationale** | Supports distributed deployment, stateless API servers, survives restarts |
| **Consequences** | (+) Distributed support, stateless servers (-) Redis dependency for rate limiting |

---

## 15. Appendices

### Appendix A: API Routes Summary

| Route | Method | Description | Status Codes | Reference |
|-------|--------|-------------|--------------|-----------|
| `/api/v1/upload` | POST | File upload, creates Job | 201, 400, 413, 415, 429 | Charter Appendix B |
| `/api/v1/process` | POST | Job initiation, returns streamUrl | 200, 400, 404, 429, 500 | Charter Appendix B |
| `/api/v1/process/[jobId]/events` | GET | SSE progress stream | 200, 404 | Charter Section 6.8 |
| `/api/v1/history` | GET | List jobs for session (paginated) | 200 | Charter Appendix B |
| `/api/v1/jobs/[id]` | GET | Get job details | 200, 404 | Charter Appendix B |
| `/api/v1/jobs/[id]/results` | GET | Get job results | 200, 404 | Charter Appendix B |
| `/api/health` | GET | Health check (cached 30s) | 200, 503 | Charter Section 8.7 |

**API Versioning**: All routes are namespaced under `/api/v1/` for future compatibility.

**Pagination Defaults** (for `/api/v1/history`):
| Parameter | Default | Max | Description |
|-----------|---------|-----|-------------|
| `page` | 1 | - | Page number (1-indexed) |
| `pageSize` | 20 | 100 | Items per page |

**Response Headers**:
- `X-Request-ID`: Correlation ID for request tracing
- `X-Total-Count`: Total items (for paginated responses)
- `X-RateLimit-Limit`: Rate limit maximum
- `X-RateLimit-Remaining`: Remaining requests in window
- `X-RateLimit-Reset`: Unix timestamp when limit resets
- `Link`: HATEOAS navigation (rel="next", rel="prev")

### Appendix B: Health Check Response

```typescript
interface HealthCheckResponse {
  status: 'healthy' | 'degraded' | 'unhealthy';
  timestamp: string;  // ISO 8601
  version: string;    // App version
  uptime: number;     // Seconds since start
  checks: {
    mcp: ServiceHealth;
    postgres: ServiceHealth;
    redis: ServiceHealth;
    fileStorage: ServiceHealth;
  };
}

interface ServiceHealth {
  status: 'ok' | 'error' | 'timeout';
  latency: number;    // Milliseconds
  message?: string;   // Error message if status !== 'ok'
  lastCheck: string;  // ISO 8601
}
```

**Reference**: Charter Section 8.7 - Health Check Implementation

### Appendix C: Cross-Reference to Charter

| Architecture Section | Charter Reference |
|---------------------|-------------------|
| System Context | Section 1, Section 8.4 |
| Container Architecture | Section 6.2, 6.3 |
| Component Architecture | Section 6.3, 6.4 |
| Infrastructure Topology | Section 8.4, 12.1 |
| Technology Stack | Section 6.1 |
| Data Architecture | Section 7 |
| Integration Patterns | Section 8 |
| Security Architecture | Section 11 |
| Error Handling | Section 6.8, 8.6, Appendix A |
| Scalability | Section 5.2, 8.1.2 |
| Deployment | Section 12 |

---

**Document Control**

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0.0 | 2025-12-11 | Alex Rivera | Initial release |
| 2.0.0 | 2025-12-11 | Alex Rivera | Gap resolution from 11-specialist review: Next.js 15 correction, Server/Client Component patterns, SSE architecture fix, MCP initialization sequence, PgBouncer configuration, database indexes, Redis authentication, accessibility, systemd service, disaster recovery, circuit breaker, checkpointing |
| 2.1.0 | 2025-12-11 | Alex Rivera | CAIO confirmation: Updated architecture to target Next.js 16 (forward-looking design), updated ADR-001 to reflect Next.js 16 capabilities, enhanced Turbopack status documentation |
